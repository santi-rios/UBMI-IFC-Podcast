{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "512041a7",
   "metadata": {},
   "source": [
    "# üéôÔ∏è Final Podcast Generation Pipeline\n",
    "\n",
    "This notebook completes the podcast generation pipeline by taking the top similarity matches from ChromaDB and generating complete podcast episodes using:\n",
    "\n",
    "## Pipeline Overview:\n",
    "1. **Load Similarity Results** - Import top matches from ChromaDB similarity search\n",
    "2. **AI-Powered Classification** - Automatically classify research fields using embeddings\n",
    "3. **Structured Script Generation** - Create consistent scientific narratives using Pydantic\n",
    "4. **Multi-Modal RAG Context** - Enhance scripts with related research context\n",
    "5. **Voice Synthesis** - Generate audio using Google's Text-to-Speech API\n",
    "6. **Complete Podcast Assembly** - Combine all elements into final podcast episodes\n",
    "\n",
    "## Scientific Purpose:\n",
    "- **Automated Content Creation**: Transform research discoveries into accessible podcast content\n",
    "- **Context-Aware Narratives**: Place new research within broader scientific landscape\n",
    "- **Standardized Quality**: Ensure consistent, high-quality scientific communication\n",
    "- **Scalable Production**: Enable regular podcast generation from ongoing research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56af22d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SETUP AND IMPORTS\n",
    "print(\"üöÄ FINAL PODCAST GENERATION PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import asyncio\n",
    "from typing import List, Dict, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add project paths\n",
    "notebook_dir = Path().resolve()\n",
    "src_dir = notebook_dir.parent / 'src'\n",
    "data_dir = notebook_dir.parent / 'notebooks/data'\n",
    "outputs_dir = notebook_dir.parent / 'outputs'\n",
    "podcast_output_dir = outputs_dir / 'final_podcasts'\n",
    "\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# Create output directories\n",
    "podcast_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Directories:\")\n",
    "print(f\"   Notebook: {notebook_dir}\")\n",
    "print(f\"   Data: {data_dir}\")\n",
    "print(f\"   Output: {podcast_output_dir}\")\n",
    "\n",
    "# Install required packages\n",
    "required_packages = ['pydantic', 'google-generativeai', 'google-cloud-texttospeech', 'pydub']\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "        print(f\"‚úÖ {package} available\")\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Installing {package}...\")\n",
    "        !pip install {package}\n",
    "        print(f\"‚úÖ {package} installed\")\n",
    "\n",
    "print(\"\\nüéØ All dependencies ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c8cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LOAD SIMILARITY SEARCH RESULTS\n",
    "print(\"üìä LOADING SIMILARITY SEARCH RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load the similarity matches from previous ChromaDB search\n",
    "similarity_search_dir = outputs_dir / 'similarity_search'\n",
    "\n",
    "def load_latest_similarity_results():\n",
    "    \"\"\"Load the most recent similarity search results\"\"\"\n",
    "    if not similarity_search_dir.exists():\n",
    "        print(f\"‚ùå Similarity search directory not found: {similarity_search_dir}\")\n",
    "        print(\"   Please run notebook 07_chromadb_similarity_search.ipynb first\")\n",
    "        return None, None\n",
    "    \n",
    "    # Find the latest results file\n",
    "    json_files = list(similarity_search_dir.glob('similarity_matches_*.json'))\n",
    "    if not json_files:\n",
    "        print(f\"‚ùå No similarity results found in {similarity_search_dir}\")\n",
    "        return None, None\n",
    "    \n",
    "    latest_file = max(json_files, key=lambda x: x.stat().st_mtime)\n",
    "    \n",
    "    with open(latest_file, 'r', encoding='utf-8') as f:\n",
    "        similarity_data = json.load(f)\n",
    "    \n",
    "    # Also load CSV for easier manipulation\n",
    "    csv_files = list(similarity_search_dir.glob('top_similarity_matches_*.csv'))\n",
    "    if csv_files:\n",
    "        latest_csv = max(csv_files, key=lambda x: x.stat().st_mtime)\n",
    "        similarity_df = pd.read_csv(latest_csv)\n",
    "    else:\n",
    "        similarity_df = pd.DataFrame()\n",
    "    \n",
    "    return similarity_data, similarity_df\n",
    "\n",
    "# Load results\n",
    "similarity_data, similarity_df = load_latest_similarity_results()\n",
    "\n",
    "if similarity_data:\n",
    "    print(f\"‚úÖ Loaded similarity results:\")\n",
    "    print(f\"   Total matches: {similarity_data['metadata']['total_matches']}\")\n",
    "    print(f\"   Top matches: {len(similarity_data['top_matches'])}\")\n",
    "    print(f\"   Generated: {similarity_data['metadata']['generated_at']}\")\n",
    "    \n",
    "    if not similarity_df.empty:\n",
    "        print(f\"   CSV data shape: {similarity_df.shape}\")\n",
    "        \n",
    "        # Show top matches\n",
    "        print(f\"\\nüìã Top 3 Similarity Matches:\")\n",
    "        for i, row in similarity_df.head(3).iterrows():\n",
    "            print(f\"   {i+1}. Similarity: {row['similarity_score']:.3f}\")\n",
    "            print(f\"      Recent: {row['query_title'][:60]}...\")\n",
    "            print(f\"      Institute: {row['matched_title'][:60]}...\")\n",
    "else:\n",
    "    print(\"‚ùå No similarity results available\")\n",
    "    print(\"   Creating mock data for demonstration...\")\n",
    "    \n",
    "    # Create mock similarity data for testing\n",
    "    similarity_data = {\n",
    "        'metadata': {\n",
    "            'generated_at': datetime.now().isoformat(),\n",
    "            'total_matches': 3,\n",
    "            'top_matches_exported': 3\n",
    "        },\n",
    "        'top_matches': [\n",
    "            {\n",
    "                'rank': 1,\n",
    "                'similarity_score': 0.756,\n",
    "                'recent_pubmed_article': {\n",
    "                    'pmid': '12345678',\n",
    "                    'title': 'Novel mechanisms of neural plasticity in adult hippocampus',\n",
    "                    'journal': 'Nature Neuroscience',\n",
    "                    'abstract': 'Recent advances in neuroimaging have revealed unprecedented insights into adult neurogenesis and synaptic plasticity. This study demonstrates novel molecular pathways that regulate hippocampal neuroplasticity, with implications for learning and memory disorders.'\n",
    "                },\n",
    "                'matched_institute_article': {\n",
    "                    'title': 'Synaptic mechanisms of memory consolidation',\n",
    "                    'journal': 'Cell',\n",
    "                    'year': 2022,\n",
    "                    'source_type': 'IFC',\n",
    "                    'authors': 'Smith J, Johnson K, Williams M'\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'rank': 2,\n",
    "                'similarity_score': 0.689,\n",
    "                'recent_pubmed_article': {\n",
    "                    'pmid': '87654321',\n",
    "                    'title': 'CRISPR-mediated gene therapy for inherited cardiac diseases',\n",
    "                    'journal': 'Science Translational Medicine',\n",
    "                    'abstract': 'Gene editing technologies offer new therapeutic approaches for inherited cardiovascular diseases. We demonstrate successful correction of disease-causing mutations in patient-derived cardiomyocytes using CRISPR-Cas9 systems.'\n",
    "                },\n",
    "                'matched_institute_article': {\n",
    "                    'title': 'Genetic basis of cardiomyopathy syndromes',\n",
    "                    'journal': 'Circulation',\n",
    "                    'year': 2021,\n",
    "                    'source_type': 'IFC',\n",
    "                    'authors': 'Brown A, Davis R, Miller T'\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Create corresponding DataFrame\n",
    "    similarity_df = pd.DataFrame([\n",
    "        {\n",
    "            'similarity_score': match['similarity_score'],\n",
    "            'query_pmid': match['recent_pubmed_article']['pmid'],\n",
    "            'query_title': match['recent_pubmed_article']['title'],\n",
    "            'query_journal': match['recent_pubmed_article']['journal'],\n",
    "            'matched_title': match['matched_institute_article']['title'],\n",
    "            'matched_journal': match['matched_institute_article']['journal'],\n",
    "            'matched_year': match['matched_institute_article']['year'],\n",
    "            'matched_source': match['matched_institute_article']['source_type']\n",
    "        }\n",
    "        for match in similarity_data['top_matches']\n",
    "    ])\n",
    "    \n",
    "    print(f\"‚úÖ Created mock similarity data for testing\")\n",
    "\n",
    "print(f\"\\nüéØ Ready to generate podcasts from {len(similarity_data['top_matches'])} matches!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
