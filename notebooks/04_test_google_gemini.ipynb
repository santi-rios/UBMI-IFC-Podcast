{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f77d0d",
   "metadata": {},
   "source": [
    "# Testing Google Gemini API Integration\n",
    "\n",
    "This notebook tests the Google Gemini API for podcast script generation with a single article.\n",
    "\n",
    "What we'll test:\n",
    "- Configuration loading and API key validation\n",
    "- Google Gemini API connectivity\n",
    "- Podcast script generation from a single article\n",
    "- Error handling and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e2624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added src to path: /home/santi/Projects/UBMI-IFC-Podcast/src\n",
      "Notebook dir: /home/santi/Projects/UBMI-IFC-Podcast/notebooks\n",
      "Src dir: /home/santi/Projects/UBMI-IFC-Podcast/src exists: True\n"
     ]
    }
   ],
   "source": [
    "# Setup: paths and imports\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "\n",
    "notebook_dir = Path().resolve()\n",
    "src_dir = notebook_dir.parent / 'src'\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "    print('Added src to path:', src_dir)\n",
    "    \n",
    "print('Notebook dir:', notebook_dir)\n",
    "print('Src dir:', src_dir, 'exists:', src_dir.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e61f0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM provider: google\n",
      "LLM model: gemini-2.5-flash\n",
      "Temperature: 0.7\n",
      "Max tokens: 4000\n",
      "\n",
      "🔍 Config diagnostic:\n",
      "api_keys section exists: True\n",
      "api_keys content: ['openai', 'anthropic', 'elevenlabs']\n",
      "google key exists: False\n",
      "❌ No Google API key found in config!\n"
     ]
    }
   ],
   "source": [
    "# Load configuration and check Google API setup\n",
    "from utils.config import load_config\n",
    "from utils.logger import setup_logger, get_logger\n",
    "\n",
    "setup_logger(level='INFO')\n",
    "logger = get_logger('gemini_test')\n",
    "config = load_config()\n",
    "\n",
    "print('LLM provider:', config['llm']['provider'])\n",
    "print('LLM model:', config['llm']['model'])\n",
    "print('Temperature:', config['llm']['temperature'])\n",
    "print('Max tokens:', config['llm']['max_tokens'])\n",
    "\n",
    "# Diagnostic: Check entire config structure\n",
    "print('\\n🔍 Config diagnostic:')\n",
    "print('api_keys section exists:', 'api_keys' in config)\n",
    "if 'api_keys' in config:\n",
    "    print('api_keys content:', list(config['api_keys'].keys()))\n",
    "    print('google key exists:', 'google' in config['api_keys'])\n",
    "    if 'google' in config['api_keys']:\n",
    "        google_key = config['api_keys']['google']\n",
    "        print('google key value:', repr(google_key))\n",
    "        print('google key length:', len(google_key))\n",
    "        print('google key is empty string:', google_key == '')\n",
    "\n",
    "# Check if Google API key is available\n",
    "google_api_key = config['api_keys'].get('google', '')\n",
    "if google_api_key:\n",
    "    print(f'✅ Google API key found: {google_api_key[:8]}...')\n",
    "else:\n",
    "    print('❌ No Google API key found in config!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48886922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test article:\n",
      "Title: Deregulation of interferon-gamma receptor 1 expression and its implications for lung adenocarcinoma progression\n",
      "Authors: Smith JA, Johnson BE, Garcia ML\n",
      "Journal: Nature Cancer\n",
      "Abstract: Interferon-gamma (IFN-γ) plays a crucial role in immune surveillance and has dual roles in cancer development and progression. This study investigates the dysregulation of IFN-γ receptor 1 (IFNGR1) ex...\n"
     ]
    }
   ],
   "source": [
    "# Test article for script generation\n",
    "test_article = {\n",
    "    'title': 'Deregulation of interferon-gamma receptor 1 expression and its implications for lung adenocarcinoma progression',\n",
    "    'abstract': 'Interferon-gamma (IFN-γ) plays a crucial role in immune surveillance and has dual roles in cancer development and progression. This study investigates the dysregulation of IFN-γ receptor 1 (IFNGR1) expression in lung adenocarcinoma and its downstream signaling pathways. We analyzed tissue samples from 150 patients and found significant downregulation of IFNGR1 in tumor tissues compared to normal lung tissue. Our results suggest that IFNGR1 deregulation contributes to immune evasion and tumor progression through altered JAK-STAT signaling.',\n",
    "    'authors': ['Smith JA', 'Johnson BE', 'Garcia ML'],\n",
    "    'journal': 'Nature Cancer',\n",
    "    'publication_date': '2024-08-15',\n",
    "    'doi': '10.5306/wjco.v15.i2.195',\n",
    "    'score': 0.95\n",
    "}\n",
    "\n",
    "print('Test article:')\n",
    "print(f\"Title: {test_article['title']}\")\n",
    "print(f\"Authors: {', '.join(test_article['authors'])}\")\n",
    "print(f\"Journal: {test_article['journal']}\")\n",
    "print(f\"Abstract: {test_article['abstract'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a7065a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file exists: True\n",
      "Raw YAML api_keys section:\n",
      "  google: AIzaSyCj...\n",
      "  openai: empty\n",
      "  anthropic: empty\n",
      "  elevenlabs: empty\n",
      "\\n✅ Google API key found after reload: AIzaSyCj...\n"
     ]
    }
   ],
   "source": [
    "# Force reload config and check raw YAML\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Load config directly from YAML file\n",
    "config_path = Path('../config/config.yaml')\n",
    "print('Config file exists:', config_path.exists())\n",
    "\n",
    "if config_path.exists():\n",
    "    with open(config_path, 'r') as f:\n",
    "        raw_config = yaml.safe_load(f)\n",
    "    \n",
    "    print('Raw YAML api_keys section:')\n",
    "    if 'api_keys' in raw_config:\n",
    "        for key, value in raw_config['api_keys'].items():\n",
    "            masked_value = f\"{value[:8]}...\" if value else \"empty\"\n",
    "            print(f\"  {key}: {masked_value}\")\n",
    "    \n",
    "    # Update our config variable\n",
    "    config = raw_config\n",
    "    google_api_key = config['api_keys'].get('google', '')\n",
    "    \n",
    "    if google_api_key:\n",
    "        print(f'\\\\n✅ Google API key found after reload: {google_api_key[:8]}...')\n",
    "    else:\n",
    "        print('\\\\n❌ Still no Google API key found!')\n",
    "else:\n",
    "    print('Config file not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebab9398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing google-generativeai...\n",
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.4/155.4 KB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-generativeai) (4.14.1)\n",
      "Requirement already satisfied: tqdm in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-generativeai) (4.67.1)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.4/155.4 KB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-generativeai) (4.14.1)\n",
      "Requirement already satisfied: tqdm in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-generativeai) (4.67.1)\n",
      "Collecting google-api-core\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 160.8/160.8 KB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-generativeai) (2.40.3)\n",
      "Collecting google-api-core\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 160.8/160.8 KB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-generativeai) (2.40.3)\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.182.0-py3-none-any.whl (14.2 MB)\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.182.0-py3-none-any.whl (14.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.2/14.2 MB 15.0 MB/s eta 0:00:00\n",
      "Collecting google-ai-generativelanguage==0.6.15\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.2/14.2 MB 15.0 MB/s eta 0:00:00\n",
      "Collecting google-ai-generativelanguage==0.6.15\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 16.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-generativeai) (6.32.0)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 16.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-generativeai) (6.32.0)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 319.9/319.9 KB 16.2 MB/s eta 0:00:00\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 319.9/319.9 KB 16.2 MB/s eta 0:00:00\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.2/50.2 KB 16.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.2/50.2 KB 16.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0\n",
      "  Downloading httplib2-0.31.0-py3-none-any.whl (91 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 91.1/91.1 KB 16.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.74.0)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2\n",
      "Collecting httplib2<1.0.0,>=0.19.0\n",
      "  Downloading httplib2-0.31.0-py3-none-any.whl (91 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 91.1/91.1 KB 16.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.74.0)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2\n",
      "  Downloading grpcio_status-1.75.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.75.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/santi/Projects/UBMI-IFC-Podcast/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: uritemplate, protobuf, httplib2, proto-plus, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.32.0\n",
      "    Uninstalling protobuf-6.32.0:\n",
      "      Successfully uninstalled protobuf-6.32.0\n",
      "Installing collected packages: uritemplate, protobuf, httplib2, proto-plus, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.32.0\n",
      "    Uninstalling protobuf-6.32.0:\n",
      "      Successfully uninstalled protobuf-6.32.0\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.25.1 google-api-python-client-2.182.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 grpcio-status-1.71.2 httplib2-0.31.0 proto-plus-1.26.1 protobuf-5.29.5 uritemplate-4.2.0\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.25.1 google-api-python-client-2.182.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 grpcio-status-1.71.2 httplib2-0.31.0 proto-plus-1.26.1 protobuf-5.29.5 uritemplate-4.2.0\n",
      "✅ google-generativeai installed successfully\n",
      "✅ google-generativeai installed successfully\n"
     ]
    }
   ],
   "source": [
    "# Install google-generativeai if needed\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    print('✅ google-generativeai is already installed')\n",
    "except ImportError:\n",
    "    print('Installing google-generativeai...')\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'google-generativeai'])\n",
    "    import google.generativeai as genai\n",
    "    print('✅ google-generativeai installed successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04074a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using legacy google.generativeai import style\n",
      "✅ Google provider initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Create a Google Gemini provider class following Google's latest API recommendations\n",
    "try:\n",
    "    # Try the new import style first (from google import genai)\n",
    "    from google import genai\n",
    "    print('✅ Using new google.genai import style')\n",
    "    NEW_API = True\n",
    "except ImportError:\n",
    "    try:\n",
    "        # Fallback to older import style  \n",
    "        import google.generativeai as genai\n",
    "        print('✅ Using legacy google.generativeai import style')\n",
    "        NEW_API = False\n",
    "    except ImportError:\n",
    "        print('❌ google-generativeai package not installed')\n",
    "        genai = None\n",
    "        NEW_API = False\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "class GoogleProvider:\n",
    "    \"\"\"Google Gemini provider using latest API recommendations\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, model: str = \"gemini-2.5-flash\"):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.logger = get_logger(__name__)\n",
    "        \n",
    "        if NEW_API:\n",
    "            # Use new Client-based API\n",
    "            self.client = genai.Client(api_key=self.api_key)\n",
    "        else:\n",
    "            # Use legacy configure-based API\n",
    "            genai.configure(api_key=self.api_key)\n",
    "            self.client = None\n",
    "        \n",
    "    async def generate_response(self, prompt: str, **kwargs) -> str:\n",
    "        \"\"\"Generate response using Google Gemini API\"\"\"\n",
    "        try:\n",
    "            if NEW_API and self.client:\n",
    "                # New API style\n",
    "                response = self.client.models.generate_content(\n",
    "                    model=self.model,\n",
    "                    contents=prompt\n",
    "                )\n",
    "                return response.text\n",
    "            else:\n",
    "                # Legacy API style\n",
    "                model = genai.GenerativeModel(self.model)\n",
    "                response = model.generate_content(\n",
    "                    prompt,\n",
    "                    generation_config=genai.types.GenerationConfig(\n",
    "                        temperature=kwargs.get('temperature', 0.7),\n",
    "                        max_output_tokens=kwargs.get('max_tokens', 4000)\n",
    "                    )\n",
    "                )\n",
    "                return response.text\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Google Gemini API error: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Test instantiation\n",
    "if genai and google_api_key:\n",
    "    try:\n",
    "        google_provider = GoogleProvider(google_api_key, config['llm']['model'])\n",
    "        print('✅ Google provider initialized successfully')\n",
    "    except Exception as e:\n",
    "        print(f'❌ Error initializing Google provider: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        google_provider = None\n",
    "else:\n",
    "    print('❌ Cannot initialize Google provider - missing dependencies or API key')\n",
    "    google_provider = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20558afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing basic API connectivity...\n",
      "✅ API Response:\n",
      "API connection successful\n",
      "✅ API Response:\n",
      "API connection successful\n"
     ]
    }
   ],
   "source": [
    "# Test basic API connectivity with a simple prompt\n",
    "if google_provider:\n",
    "    simple_test_prompt = \"Hello! Please respond with 'API connection successful' if you can read this.\"\n",
    "    \n",
    "    try:\n",
    "        print('Testing basic API connectivity...')\n",
    "        response = await google_provider.generate_response(simple_test_prompt)\n",
    "        print('✅ API Response:')\n",
    "        print(response)\n",
    "    except Exception as e:\n",
    "        print(f'❌ API connectivity test failed: {e}')\n",
    "else:\n",
    "    print('❌ Skipping connectivity test - no provider available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc1b232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Script generator initialized\n"
     ]
    }
   ],
   "source": [
    "# Create a simple podcast script generator for testing\n",
    "class SimplePodcastScriptGenerator:\n",
    "    \"\"\"Simplified podcast script generator for testing Google Gemini\"\"\"\n",
    "    \n",
    "    def __init__(self, provider, config):\n",
    "        self.provider = provider\n",
    "        self.config = config\n",
    "        self.logger = get_logger(__name__)\n",
    "        \n",
    "    def _prepare_article_summary(self, article: Dict) -> str:\n",
    "        \"\"\"Prepare a summary of the article for the prompt\"\"\"\n",
    "        summary = f\"\"\"\n",
    "Article:\n",
    "Title: {article.get('title', 'N/A')}\n",
    "Authors: {', '.join(article.get('authors', [])) if article.get('authors') else 'N/A'}\n",
    "Journal: {article.get('journal', 'N/A')}\n",
    "Publication Date: {article.get('publication_date', 'N/A')}\n",
    "DOI: {article.get('doi', 'N/A')}\n",
    "\n",
    "Abstract:\n",
    "{article.get('abstract', 'No abstract available')}\n",
    "\"\"\"\n",
    "        return summary.strip()\n",
    "    \n",
    "    def _build_podcast_prompt(self, article_summary: str) -> str:\n",
    "        \"\"\"Build the prompt for podcast script generation\"\"\"\n",
    "        template = self.config['llm']['podcast_prompt_template']\n",
    "        return template.format(articles=article_summary)\n",
    "    \n",
    "    async def generate_podcast_script(self, article: Dict) -> str:\n",
    "        \"\"\"Generate podcast script from a single article\"\"\"\n",
    "        self.logger.info(f\"Generating podcast script for article: {article.get('title', 'Unknown')}\")\n",
    "        \n",
    "        # Prepare article summary\n",
    "        article_summary = self._prepare_article_summary(article)\n",
    "        \n",
    "        # Build prompt\n",
    "        prompt = self._build_podcast_prompt(article_summary)\n",
    "        \n",
    "        print('--- Generated Prompt ---')\n",
    "        print(prompt[:500] + '...' if len(prompt) > 500 else prompt)\n",
    "        print('\\n--- Sending to Gemini API ---')\n",
    "        \n",
    "        # Generate script\n",
    "        script = await self.provider.generate_response(\n",
    "            prompt,\n",
    "            temperature=self.config['llm']['temperature'],\n",
    "            max_tokens=self.config['llm']['max_tokens']\n",
    "        )\n",
    "        \n",
    "        self.logger.info(\"Podcast script generated successfully\")\n",
    "        return script\n",
    "\n",
    "# Initialize the generator\n",
    "if google_provider:\n",
    "    script_generator = SimplePodcastScriptGenerator(google_provider, config)\n",
    "    print('✅ Script generator initialized')\n",
    "else:\n",
    "    print('❌ Cannot initialize script generator without provider')\n",
    "    script_generator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02e35c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 18:02:09\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_podcast_script\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mGenerating podcast script for article: Deregulation of interferon-gamma receptor 1 expression and its implications for lung adenocarcinoma progression\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating podcast script...\n",
      "--- Generated Prompt ---\n",
      "You are a science communicator creating a podcast script about recent research.\n",
      "Create an engaging 5-minute podcast script summarizing these research articles:\n",
      "\n",
      "Article:\n",
      "Title: Deregulation of interferon-gamma receptor 1 expression and its implications for lung adenocarcinoma progression\n",
      "Authors: Smith JA, Johnson BE, Garcia ML\n",
      "Journal: Nature Cancer\n",
      "Publication Date: 2024-08-15\n",
      "DOI: 10.5306/wjco.v15.i2.195\n",
      "\n",
      "Abstract:\n",
      "Interferon-gamma (IFN-γ) plays a crucial role in immune surveillance and has d...\n",
      "\n",
      "--- Sending to Gemini API ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 18:02:31\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_podcast_script\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mPodcast script generated successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GENERATED PODCAST SCRIPT\n",
      "============================================================\n",
      "**(Intro Music fades in and out)**\n",
      "\n",
      "**Host:** Welcome to \"Science Unpacked,\" the podcast that brings the latest breakthroughs from the lab bench directly to your ears! I'm your host, [Your Name/Podcast Host Name], and today, we're diving into some fascinating new research that sheds light on how lung cancer outsmarts our immune system, and what that could mean for future treatments.\n",
      "\n",
      "**(Pause for effect)**\n",
      "\n",
      "**Host:** Our immune system is an incredible defense force, constantly patrolling for threats, including rogue cancer cells. But cancer is notoriously clever, often finding ways to evade detection and destruction. A groundbreaking study, published just last month in *Nature Cancer* by a team including Smith, Johnson, and Garcia, has uncovered a key mechanism behind this evasion in lung adenocarcinoma, a common and aggressive form of lung cancer.\n",
      "\n",
      "**(Main Findings - 2 minutes)**\n",
      "\n",
      "**Host:** So, what did they find? Let's start with a crucial player in our immune defense: a molecule called **Interferon-gamma**, or **IFN-γ** for short. Think of IFN-γ as a powerful alarm signal. When your immune cells detect a problem, like a tumor, they release IFN-γ, which then travels to other cells, including the cancer cells themselves. Its job is to tell those cells to stop growing, or even to self-destruct. It’s a critical part of how our body tries to fight cancer.\n",
      "\n",
      "But for IFN-γ to do its job, the target cell needs a way to \"hear\" the alarm. That's where **IFN-gamma receptor 1**, or **IFNGR1**, comes in. Imagine IFNGR1 as an antenna or a doorway on the surface of a cell. IFN-γ binds to this receptor, and that connection triggers a cascade of internal communication within the cell – a pathway known as **JAK-STAT signaling**. This signaling pathway is like the cell's internal switchboard, directing it to respond appropriately to the immune alarm.\n",
      "\n",
      "Now, here's the crucial discovery from this study. The researchers analyzed tissue samples from 150 patients with lung adenocarcinoma. They compared the tumor tissues with normal, healthy lung tissue from the same patients. What they found was striking: there was a **significant downregulation of IFNGR1** in the tumor tissues.\n",
      "\n",
      "In simpler terms, the cancer cells had far fewer of these \"antennas\" or \"doorways\" on their surface. It's like the cancer cells were deliberately turning down the volume on the immune system's alarm signal, making it harder for them to hear the crucial instructions from IFN-γ. This downregulation, they found, disrupted that vital JAK-STAT signaling pathway inside the cells.\n",
      "\n",
      "**(Implications - 1.5 minutes)**\n",
      "\n",
      "**Host:** So, why is this finding so important? Well, if cancer cells can't properly receive the IFN-γ alarm, they can effectively **evade the immune system**. They can continue to grow and spread unchecked, even while our immune system is trying to fight them. This mechanism of immune evasion is a major hurdle in cancer treatment, and understanding *how* it happens is the first step towards overcoming it.\n",
      "\n",
      "This research opens up exciting new avenues for potential therapies. If we know that lung adenocarcinoma cells are deliberately reducing their IFNGR1 receptors, perhaps we can develop strategies to counteract this.\n",
      "\n",
      "For instance:\n",
      "*   Could we find ways to **upregulate IFNGR1** in tumor cells, forcing them to \"listen\" to the immune alarm again?\n",
      "*   Or, could we develop treatments that **bypass the receptor entirely** and directly activate the crucial JAK-STAT signaling pathway within the cancer cells, even when the receptor is low?\n",
      "*   This insight could also help us better understand why some patients respond well to existing immunotherapies, while others don't. It might even lead to more **personalized treatment approaches**, where we specifically target this IFNGR1 pathway in patients whose tumors exhibit this downregulation.\n",
      "\n",
      "**(Conclusion - 45 seconds)**\n",
      "\n",
      "**Host:** The deregulation of IFNGR1 in lung adenocarcinoma is a clever trick employed by cancer cells to hide from our immune defenses. But thanks to dedicated researchers like Smith, Johnson, and Garcia, we're beginning to understand these tricks better. This study isn't just a fascinating piece of biology; it's a beacon of hope, pointing towards new strategies to empower our immune system and ultimately, improve the lives of those affected by lung cancer.\n",
      "\n",
      "That’s all for this episode of \"Science Unpacked.\" Join us next time as we continue to explore the incredible world of scientific discovery.\n",
      "\n",
      "**(Outro Music fades in)**\n",
      "============================================================\n",
      "\n",
      "📊 Script Statistics:\n",
      "Word count: 708\n",
      "Character count: 4524\n",
      "Estimated reading time: 4.7 minutes\n",
      "Key elements found: ['findings', 'implications', 'conclusion']\n"
     ]
    }
   ],
   "source": [
    "# Generate podcast script from the test article\n",
    "if script_generator:\n",
    "    try:\n",
    "        print('Generating podcast script...')\n",
    "        podcast_script = await script_generator.generate_podcast_script(test_article)\n",
    "        \n",
    "        print('\\n' + '='*60)\n",
    "        print('GENERATED PODCAST SCRIPT')\n",
    "        print('='*60)\n",
    "        print(podcast_script)\n",
    "        print('='*60)\n",
    "        \n",
    "        # Basic quality checks\n",
    "        word_count = len(podcast_script.split())\n",
    "        print(f'\\n📊 Script Statistics:')\n",
    "        print(f'Word count: {word_count}')\n",
    "        print(f'Character count: {len(podcast_script)}')\n",
    "        print(f'Estimated reading time: {word_count / 150:.1f} minutes')\n",
    "        \n",
    "        # Check if key elements are present\n",
    "        key_elements = ['introduction', 'findings', 'implications', 'conclusion']\n",
    "        found_elements = [elem for elem in key_elements if elem.lower() in podcast_script.lower()]\n",
    "        print(f'Key elements found: {found_elements}')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'❌ Error generating podcast script: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print('❌ Skipping script generation - no script generator available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1192ef79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 18:02:47\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_podcast_script\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mGenerating podcast script for article: \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing error handling...\n",
      "--- Generated Prompt ---\n",
      "You are a science communicator creating a podcast script about recent research.\n",
      "Create an engaging 5-minute podcast script summarizing these research articles:\n",
      "\n",
      "Article:\n",
      "Title: \n",
      "Authors: N/A\n",
      "Journal: N/A\n",
      "Publication Date: N/A\n",
      "DOI: N/A\n",
      "\n",
      "Abstract:\n",
      "\n",
      "Format: Introduction, main findings, implications, conclusion.\n",
      "Tone: Professional but accessible to a general audience.\n",
      "\n",
      "\n",
      "--- Sending to Gemini API ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 18:03:14\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_podcast_script\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mPodcast script generated successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Handled empty article gracefully\n",
      "Response length: 4641 characters\n",
      "\n",
      "✅ Error handling tests completed\n"
     ]
    }
   ],
   "source": [
    "# Test error handling and edge cases\n",
    "if google_provider:\n",
    "    print('Testing error handling...')\n",
    "    \n",
    "    # Test with empty article\n",
    "    empty_article = {'title': '', 'abstract': ''}\n",
    "    \n",
    "    try:\n",
    "        empty_script = await script_generator.generate_podcast_script(empty_article)\n",
    "        print('✅ Handled empty article gracefully')\n",
    "        print(f'Response length: {len(empty_script)} characters')\n",
    "    except Exception as e:\n",
    "        print(f'❌ Error with empty article: {e}')\n",
    "    \n",
    "    # Test with very long prompt (if needed)\n",
    "    # This helps understand API limits\n",
    "    print('\\n✅ Error handling tests completed')\n",
    "else:\n",
    "    print('❌ Skipping error handling tests - no provider available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e49af03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST SUMMARY\n",
      "============================================================\n",
      "✅ Google Gemini API integration: SUCCESS\n",
      "✅ Podcast script generation: SUCCESS\n",
      "✅ Configuration loading: SUCCESS\n",
      "\n",
      "📝 Next steps:\n",
      "1. Integrate GoogleProvider into the main script_generator.py\n",
      "2. Test with multiple articles\n",
      "3. Test with real scraped data from IFC/PubMed\n",
      "4. Optimize prompt template for better results\n",
      "5. Add more error handling and logging\n",
      "\n",
      "📋 Configuration used:\n",
      "Provider: google\n",
      "Model: gemini-2.5-flash\n",
      "Temperature: 0.7\n",
      "Max tokens: 4000\n"
     ]
    }
   ],
   "source": [
    "# Summary and next steps\n",
    "print('\\n' + '='*60)\n",
    "print('TEST SUMMARY')\n",
    "print('='*60)\n",
    "\n",
    "if google_provider:\n",
    "    print('✅ Google Gemini API integration: SUCCESS')\n",
    "    print('✅ Podcast script generation: SUCCESS')\n",
    "    print('✅ Configuration loading: SUCCESS')\n",
    "    \n",
    "    print('\\n📝 Next steps:')\n",
    "    print('1. Integrate GoogleProvider into the main script_generator.py')\n",
    "    print('2. Test with multiple articles')\n",
    "    print('3. Test with real scraped data from IFC/PubMed')\n",
    "    print('4. Optimize prompt template for better results')\n",
    "    print('5. Add more error handling and logging')\n",
    "else:\n",
    "    print('❌ Google Gemini API integration: FAILED')\n",
    "    print('\\n🔧 Required fixes:')\n",
    "    print('1. Check Google API key in config.yaml')\n",
    "    print('2. Verify internet connectivity')\n",
    "    print('3. Check API quotas and billing')\n",
    "    print('4. Install google-generativeai package')\n",
    "\n",
    "print('\\n📋 Configuration used:')\n",
    "print(f'Provider: {config[\"llm\"][\"provider\"]}')\n",
    "print(f'Model: {config[\"llm\"][\"model\"]}')\n",
    "print(f'Temperature: {config[\"llm\"][\"temperature\"]}')\n",
    "print(f'Max tokens: {config[\"llm\"][\"max_tokens\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
