{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ™ï¸ Final Podcast Generation Pipeline\n",
    "\n",
    "This notebook completes the podcast generation pipeline by taking the top similarity matches from ChromaDB and generating complete podcast episodes using:\n",
    "\n",
    "## Pipeline Overview:\n",
    "1. **Load Similarity Results** - Import top matches from ChromaDB similarity search\n",
    "2. **AI-Powered Classification** - Automatically classify research fields using embeddings\n",
    "3. **Structured Script Generation** - Create consistent scientific narratives using Pydantic\n",
    "4. **Multi-Modal RAG Context** - Enhance scripts with related research context\n",
    "5. **Voice Synthesis** - Generate audio using Google's Text-to-Speech API\n",
    "6. **Complete Podcast Assembly** - Combine all elements into final podcast episodes\n",
    "\n",
    "## Scientific Purpose:\n",
    "- **Automated Content Creation**: Transform research discoveries into accessible podcast content\n",
    "- **Context-Aware Narratives**: Place new research within broader scientific landscape\n",
    "- **Standardized Quality**: Ensure consistent, high-quality scientific communication\n",
    "- **Scalable Production**: Enable regular podcast generation from ongoing research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SETUP AND IMPORTS\n",
    "print(\"ðŸš€ FINAL PODCAST GENERATION PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import asyncio\n",
    "from typing import List, Dict, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add project paths\n",
    "notebook_dir = Path().resolve()\n",
    "src_dir = notebook_dir.parent / 'src'\n",
    "data_dir = notebook_dir.parent / 'notebooks/data'\n",
    "outputs_dir = notebook_dir.parent / 'outputs'\n",
    "podcast_output_dir = outputs_dir / 'final_podcasts'\n",
    "\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# Create output directories\n",
    "podcast_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"ðŸ“ Directories:\")\n",
    "print(f\"   Notebook: {notebook_dir}\")\n",
    "print(f\"   Data: {data_dir}\")\n",
    "print(f\"   Output: {podcast_output_dir}\")\n",
    "\n",
    "# Install required packages\n",
    "required_packages = ['pydantic', 'google-generativeai', 'google-cloud-texttospeech', 'pydub']\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "        print(f\"âœ… {package} available\")\n",
    "    except ImportError:\n",
    "        print(f\"ðŸ“¦ Installing {package}...\")\n",
    "        !pip install {package}\n",
    "        print(f\"âœ… {package} installed\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ All dependencies ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LOAD SIMILARITY SEARCH RESULTS\n",
    "print(\"ðŸ“Š LOADING SIMILARITY SEARCH RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load the similarity matches from previous ChromaDB search\n",
    "similarity_search_dir = outputs_dir / 'similarity_search'\n",
    "\n",
    "def load_latest_similarity_results():\n",
    "    \"\"\"Load the most recent similarity search results\"\"\"\n",
    "    if not similarity_search_dir.exists():\n",
    "        print(f\"âŒ Similarity search directory not found: {similarity_search_dir}\")\n",
    "        print(\"   Please run notebook 07_chromadb_similarity_search.ipynb first\")\n",
    "        return None, None\n",
    "    \n",
    "    # Find the latest results file\n",
    "    json_files = list(similarity_search_dir.glob('similarity_matches_*.json'))\n",
    "    if not json_files:\n",
    "        print(f\"âŒ No similarity results found in {similarity_search_dir}\")\n",
    "        return None, None\n",
    "    \n",
    "    latest_file = max(json_files, key=lambda x: x.stat().st_mtime)\n",
    "    \n",
    "    with open(latest_file, 'r', encoding='utf-8') as f:\n",
    "        similarity_data = json.load(f)\n",
    "    \n",
    "    # Also load CSV for easier manipulation\n",
    "    csv_files = list(similarity_search_dir.glob('top_similarity_matches_*.csv'))\n",
    "    if csv_files:\n",
    "        latest_csv = max(csv_files, key=lambda x: x.stat().st_mtime)\n",
    "        similarity_df = pd.read_csv(latest_csv)\n",
    "    else:\n",
    "        similarity_df = pd.DataFrame()\n",
    "    \n",
    "    return similarity_data, similarity_df\n",
    "\n",
    "# Load results\n",
    "similarity_data, similarity_df = load_latest_similarity_results()\n",
    "\n",
    "if similarity_data:\n",
    "    print(f\"âœ… Loaded similarity results:\")\n",
    "    print(f\"   Total matches: {similarity_data['metadata']['total_matches']}\")\n",
    "    print(f\"   Top matches: {len(similarity_data['top_matches'])}\")\n",
    "    print(f\"   Generated: {similarity_data['metadata']['generated_at']}\")\n",
    "    \n",
    "    if not similarity_df.empty:\n",
    "        print(f\"   CSV data shape: {similarity_df.shape}\")\n",
    "        \n",
    "        # Show top matches\n",
    "        print(f\"\\nðŸ“‹ Top 3 Similarity Matches:\")\n",
    "        for i, row in similarity_df.head(3).iterrows():\n",
    "            print(f\"   {i+1}. Similarity: {row['similarity_score']:.3f}\")\n",
    "            print(f\"      Recent: {row['query_title'][:60]}...\")\n",
    "            print(f\"      Institute: {row['matched_title'][:60]}...\")\n",
    "else:\n",
    "    print(\"âŒ No similarity results available\")\n",
    "    print(\"   Creating mock data for demonstration...\")\n",
    "    \n",
    "    # Create mock similarity data for testing\n",
    "    similarity_data = {\n",
    "        'metadata': {\n",
    "            'generated_at': datetime.now().isoformat(),\n",
    "            'total_matches': 3,\n",
    "            'top_matches_exported': 3\n",
    "        },\n",
    "        'top_matches': [\n",
    "            {\n",
    "                'rank': 1,\n",
    "                'similarity_score': 0.756,\n",
    "                'recent_pubmed_article': {\n",
    "                    'pmid': '12345678',\n",
    "                    'title': 'Novel mechanisms of neural plasticity in adult hippocampus',\n",
    "                    'journal': 'Nature Neuroscience',\n",
    "                    'abstract': 'Recent advances in neuroimaging have revealed unprecedented insights into adult neurogenesis and synaptic plasticity. This study demonstrates novel molecular pathways that regulate hippocampal neuroplasticity, with implications for learning and memory disorders.'\n",
    "                },\n",
    "                'matched_institute_article': {\n",
    "                    'title': 'Synaptic mechanisms of memory consolidation',\n",
    "                    'journal': 'Cell',\n",
    "                    'year': 2022,\n",
    "                    'source_type': 'IFC',\n",
    "                    'authors': 'Smith J, Johnson K, Williams M'\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'rank': 2,\n",
    "                'similarity_score': 0.689,\n",
    "                'recent_pubmed_article': {\n",
    "                    'pmid': '87654321',\n",
    "                    'title': 'CRISPR-mediated gene therapy for inherited cardiac diseases',\n",
    "                    'journal': 'Science Translational Medicine',\n",
    "                    'abstract': 'Gene editing technologies offer new therapeutic approaches for inherited cardiovascular diseases. We demonstrate successful correction of disease-causing mutations in patient-derived cardiomyocytes using CRISPR-Cas9 systems.'\n",
    "                },\n",
    "                'matched_institute_article': {\n",
    "                    'title': 'Genetic basis of cardiomyopathy syndromes',\n",
    "                    'journal': 'Circulation',\n",
    "                    'year': 2021,\n",
    "                    'source_type': 'IFC',\n",
    "                    'authors': 'Brown A, Davis R, Miller T'\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Create corresponding DataFrame\n",
    "    similarity_df = pd.DataFrame([\n",
    "        {\n",
    "            'similarity_score': match['similarity_score'],\n",
    "            'query_pmid': match['recent_pubmed_article']['pmid'],\n",
    "            'query_title': match['recent_pubmed_article']['title'],\n",
    "            'query_journal': match['recent_pubmed_article']['journal'],\n",
    "            'matched_title': match['matched_institute_article']['title'],\n",
    "            'matched_journal': match['matched_institute_article']['journal'],\n",
    "            'matched_year': match['matched_institute_article']['year'],\n",
    "            'matched_source': match['matched_institute_article']['source_type']\n",
    "        }\n",
    "        for match in similarity_data['top_matches']\n",
    "    ])\n",
    "    \n",
    "    print(f\"âœ… Created mock similarity data for testing\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Ready to generate podcasts from {len(similarity_data['top_matches'])} matches!\")"
   ]
  },
    {
      "id": "VSC-3. API SETUP",
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. API SETUP AND PROVIDERS\n",
        "print(\"ðŸ”‘ SETTING UP API PROVIDERS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.cloud import texttospeech\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "# Setup Google Gemini API\n",
        "def setup_gemini_api():\n",
        "    \"\"\"Setup Gemini API for text generation\"\"\"\n",
        "    try:\n",
        "        # Try to get API key from environment\n",
        "        api_key = os.getenv('GOOGLE_API_KEY') or os.getenv('GEMINI_API_KEY')\n",
        "        if not api_key:\n",
        "            print(\"âš ï¸ No API key found. Using mock provider for testing.\")\n",
        "            return None\n",
        "        \n",
        "        genai.configure(api_key=api_key)\n",
        "        model = genai.GenerativeModel('gemini-1.5-pro')\n",
        "        print(\"âœ… Gemini API configured successfully\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Gemini API setup failed: {e}. Using mock provider.\")\n",
        "        return None\n",
        "\n",
        "# Setup Google Cloud Text-to-Speech\n",
        "def setup_tts_client():\n",
        "    \"\"\"Setup Google Cloud Text-to-Speech client\"\"\"\n",
        "    try:\n",
        "        client = texttospeech.TextToSpeechClient()\n",
        "        print(\"âœ… Google Cloud TTS configured successfully\")\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Google Cloud TTS setup failed: {e}. Using mock TTS.\")\n",
        "        return None\n",
        "\n",
        "# Initialize providers\n",
        "gemini_model = setup_gemini_api()\n",
        "tts_client = setup_tts_client()\n",
        "\n",
        "print(f\"\\nðŸŽ¯ API Status:\")\n",
        "print(f\"   Gemini: {'âœ… Ready' if gemini_model else 'ðŸ”§ Mock mode'}\")\n",
        "print(f\"   Text-to-Speech: {'âœ… Ready' if tts_client else 'ðŸ”§ Mock mode'}\")"
      ]
    },
    {
      "id": "VSC-4. STRUCTURED SCRIPT MODELS",
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. STRUCTURED SCRIPT GENERATION WITH PYDANTIC\n",
        "print(\"ðŸ“ DEFINING STRUCTURED SCRIPT MODELS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "class PodcastScriptStructure(BaseModel):\n",
        "    \"\"\"Structured output schema for scientific podcast scripts\"\"\"\n",
        "    \n",
        "    podcast_title: str = Field(\n",
        "        description=\"Engaging, accessible title for the podcast episode\",\n",
        "        min_length=10,\n",
        "        max_length=100\n",
        "    )\n",
        "    \n",
        "    introduction: str = Field(\n",
        "        description=\"Hook to grab listener attention, introducing the research topic and importance\",\n",
        "        min_length=100,\n",
        "        max_length=500\n",
        "    )\n",
        "    \n",
        "    research_context: str = Field(\n",
        "        description=\"Background on the research field and why this work matters\",\n",
        "        min_length=100,\n",
        "        max_length=400\n",
        "    )\n",
        "    \n",
        "    methods_summary: str = Field(\n",
        "        description=\"Simplified explanation of key research methods, avoiding jargon\",\n",
        "        min_length=50,\n",
        "        max_length=300\n",
        "    )\n",
        "    \n",
        "    key_findings: List[str] = Field(\n",
        "        description=\"List of 2-4 main results or discoveries, explained clearly\",\n",
        "        min_items=2,\n",
        "        max_items=4\n",
        "    )\n",
        "    \n",
        "    institute_connection: str = Field(\n",
        "        description=\"How this research connects to your institute's work\",\n",
        "        min_length=50,\n",
        "        max_length=300\n",
        "    )\n",
        "    \n",
        "    implications_and_significance: str = Field(\n",
        "        description=\"Why these findings matter for science and the public\",\n",
        "        min_length=100,\n",
        "        max_length=400\n",
        "    )\n",
        "    \n",
        "    conclusion: str = Field(\n",
        "        description=\"Summary and concluding thought to leave listeners with\",\n",
        "        min_length=50,\n",
        "        max_length=200\n",
        "    )\n",
        "\n",
        "print(\"âœ… Structured script models defined\")\n",
        "print(f\"   Sections: {len(PodcastScriptStructure.model_fields)} required fields\")\n",
        "print(f\"   Validation: Automatic length and content validation\")\n",
        "print(f\"   Output: Consistent, high-quality scientific narratives\")"
      ]
    },
    {
      "id": "VSC-5. SCRIPT GENERATOR",
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. INTELLIGENT SCRIPT GENERATOR\n",
        "print(\"ðŸ§  CREATING INTELLIGENT SCRIPT GENERATOR\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "class PodcastScriptGenerator:\n",
        "    \"\"\"Generate structured podcast scripts from similarity matches\"\"\"\n",
        "    \n",
        "    def __init__(self, model=None):\n",
        "        self.model = model\n",
        "        self.use_mock = model is None\n",
        "    \n",
        "    async def generate_script(self, similarity_match: Dict) -> PodcastScriptStructure:\n",
        "        \"\"\"Generate a structured podcast script from a similarity match\"\"\"\n",
        "        \n",
        "        recent_article = similarity_match['recent_pubmed_article']\n",
        "        institute_article = similarity_match['matched_institute_article']\n",
        "        similarity_score = similarity_match['similarity_score']\n",
        "        \n",
        "        if self.use_mock:\n",
        "            return self._generate_mock_script(recent_article, institute_article, similarity_score)\n",
        "        \n",
        "        # Real Gemini generation\n",
        "        prompt = self._build_generation_prompt(recent_article, institute_article, similarity_score)\n",
        "        \n",
        "        try:\n",
        "            response = await self.model.generate_content_async(\n",
        "                prompt,\n",
        "                generation_config=genai.GenerationConfig(\n",
        "                    response_mime_type=\"application/json\",\n",
        "                    response_schema=PodcastScriptStructure\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            script_data = json.loads(response.text)\n",
        "            return PodcastScriptStructure.model_validate(script_data)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Gemini generation failed: {e}. Using mock script.\")\n",
        "            return self._generate_mock_script(recent_article, institute_article, similarity_score)\n",
        "    \n",
        "    def _build_generation_prompt(self, recent_article: Dict, institute_article: Dict, similarity_score: float) -> str:\n",
        "        \"\"\"Build the generation prompt for Gemini\"\"\"\n",
        "        return f\"\"\"\n",
        "You are an expert science communicator creating a podcast script about cutting-edge research.\n",
        "\n",
        "RECENT RESEARCH (from PubMed):\n",
        "Title: {recent_article['title']}\n",
        "Journal: {recent_article['journal']}\n",
        "Abstract: {recent_article.get('abstract', 'Abstract not available')}\n",
        "PMID: {recent_article['pmid']}\n",
        "\n",
        "RELATED INSTITUTE WORK:\n",
        "Title: {institute_article['title']}\n",
        "Journal: {institute_article['journal']}\n",
        "Year: {institute_article['year']}\n",
        "Authors: {institute_article.get('authors', 'Authors not available')}\n",
        "\n",
        "SIMILARITY SCORE: {similarity_score:.3f} (indicates strong thematic connection)\n",
        "\n",
        "Create an engaging podcast script that:\n",
        "1. Makes complex science accessible to a general audience\n",
        "2. Highlights the connection between recent research and institute work\n",
        "3. Explains the significance and real-world implications\n",
        "4. Uses conversational, engaging tone suitable for audio\n",
        "5. Includes natural transitions between sections\n",
        "\n",
        "Return the response as JSON matching the PodcastScriptStructure schema.\n",
        "\"\"\"\n",
        "    \n",
        "    def _generate_mock_script(self, recent_article: Dict, institute_article: Dict, similarity_score: float) -> PodcastScriptStructure:\n",
        "        \"\"\"Generate a mock script for testing\"\"\"\n",
        "        \n",
        "        title = recent_article['title']\n",
        "        field_keywords = {\n",
        "            'neural': 'neuroscience',\n",
        "            'brain': 'neuroscience', \n",
        "            'cancer': 'oncology',\n",
        "            'tumor': 'oncology',\n",
        "            'immune': 'immunology',\n",
        "            'gene': 'genetics',\n",
        "            'heart': 'cardiology'\n",
        "        }\n",
        "        \n",
        "        # Determine field\n",
        "        field = 'biomedical research'\n",
        "        for keyword, detected_field in field_keywords.items():\n",
        "            if keyword in title.lower():\n",
        "                field = detected_field\n",
        "                break\n",
        "        \n",
        "        return PodcastScriptStructure(\n",
        "            podcast_title=f\"Breakthrough in {field.title()}: {title[:50]}...\",\n",
        "            introduction=f\"Welcome to Research Frontiers, where we explore the latest breakthroughs in {field}. Today, we're diving into exciting new research published in {recent_article['journal']} that could change how we understand and treat diseases.\",\n",
        "            research_context=f\"The field of {field} has been rapidly evolving, with researchers around the world working to unlock new therapeutic possibilities. This latest study represents a significant step forward in our understanding.\",\n",
        "            methods_summary=f\"The researchers used cutting-edge techniques to investigate the underlying mechanisms. Their innovative approach allowed them to observe cellular processes in unprecedented detail.\",\n",
        "            key_findings=[\n",
        "                f\"The study revealed novel mechanisms that could lead to new therapeutic targets\",\n",
        "                f\"Researchers identified key molecular pathways involved in the disease process\",\n",
        "                f\"The findings suggest potential for developing more effective treatments\"\n",
        "            ],\n",
        "            institute_connection=f\"This research connects beautifully with work being done at our institute. Our team's previous study on '{institute_article['title']}' laid important groundwork that makes these new findings even more significant.\",\n",
        "            implications_and_significance=f\"These discoveries have profound implications for patients and the broader scientific community. By understanding these mechanisms better, we're moving closer to personalized medicine approaches that could transform treatment outcomes.\",\n",
        "            conclusion=f\"This research demonstrates the power of scientific collaboration and innovation. As we continue to build on these findings, we're optimistic about the potential for breakthrough treatments in the near future.\"\n",
        "        )\n",
        "\n",
        "# Initialize script generator\n",
        "script_generator = PodcastScriptGenerator(gemini_model)\n",
        "\n",
        "print(f\"âœ… Script generator initialized\")\n",
        "print(f\"   Mode: {'ðŸ¤– AI-powered' if not script_generator.use_mock else 'ðŸ”§ Mock generation'}\")\n",
        "print(f\"   Output: Structured, validated podcast scripts\")"
      ]
    },
    {
      "id": "VSC-6. VOICE SYNTHESIS",
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. VOICE SYNTHESIS SYSTEM\n",
        "print(\"ðŸŽ™ï¸ SETTING UP VOICE SYNTHESIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "import base64\n",
        "from pydub import AudioSegment\n",
        "import io\n",
        "\n",
        "class VoiceSynthesizer:\n",
        "    \"\"\"Handle text-to-speech conversion for podcast generation\"\"\"\n",
        "    \n",
        "    def __init__(self, tts_client=None):\n",
        "        self.client = tts_client\n",
        "        self.use_mock = tts_client is None\n",
        "        \n",
        "        # Voice configuration\n",
        "        self.voice_config = texttospeech.VoiceSelectionParams(\n",
        "            language_code=\"en-US\",\n",
        "            name=\"en-US-Studio-M\",  # Professional male voice\n",
        "            ssml_gender=texttospeech.SsmlVoiceGender.MALE\n",
        "        ) if not self.use_mock else None\n",
        "        \n",
        "        self.audio_config = texttospeech.AudioConfig(\n",
        "            audio_encoding=texttospeech.AudioEncoding.MP3,\n",
        "            speaking_rate=0.9,  # Slightly slower for clarity\n",
        "            pitch=0.0,\n",
        "            volume_gain_db=0.0\n",
        "        ) if not self.use_mock else None\n",
        "    \n",
        "    def script_to_ssml(self, script: PodcastScriptStructure) -> str:\n",
        "        \"\"\"Convert structured script to SSML for better speech synthesis\"\"\"\n",
        "        \n",
        "        ssml_parts = [\n",
        "            '<speak>',\n",
        "            \n",
        "            # Title with emphasis\n",
        "            f'<emphasis level=\"strong\">{script.podcast_title}</emphasis>',\n",
        "            '<break time=\"2s\"/>',\n",
        "            \n",
        "            # Introduction\n",
        "            script.introduction,\n",
        "            '<break time=\"1s\"/>',\n",
        "            \n",
        "            # Research context\n",
        "            script.research_context,\n",
        "            '<break time=\"1s\"/>',\n",
        "            \n",
        "            # Methods\n",
        "            'Now, let me explain how the researchers approached this problem.',\n",
        "            '<break time=\"0.5s\"/>',\n",
        "            script.methods_summary,\n",
        "            '<break time=\"1s\"/>',\n",
        "            \n",
        "            # Key findings\n",
        "            'So what did they discover? Here are the key findings:',\n",
        "            '<break time=\"0.5s\"/>'\n",
        "        ]\n",
        "        \n",
        "        # Add findings with pauses\n",
        "        for i, finding in enumerate(script.key_findings, 1):\n",
        "            ssml_parts.extend([\n",
        "                f'First, {finding}' if i == 1 else f'Second, {finding}' if i == 2 else f'Third, {finding}' if i == 3 else f'Finally, {finding}',\n",
        "                '<break time=\"0.8s\"/>'\n",
        "            ])\n",
        "        \n",
        "        ssml_parts.extend([\n",
        "            # Institute connection\n",
        "            script.institute_connection,\n",
        "            '<break time=\"1s\"/>',\n",
        "            \n",
        "            # Implications\n",
        "            script.implications_and_significance,\n",
        "            '<break time=\"1s\"/>',\n",
        "            \n",
        "            # Conclusion\n",
        "            script.conclusion,\n",
        "            '<break time=\"1s\"/>',\n",
        "            \n",
        "            'Thank you for listening to Research Frontiers.',\n",
        "            '</speak>'\n",
        "        ])\n",
        "        \n",
        "        return ' '.join(ssml_parts)\n",
        "    \n",
        "    async def synthesize_speech(self, script: PodcastScriptStructure, output_path: Path) -> bool:\n",
        "        \"\"\"Convert script to audio file\"\"\"\n",
        "        \n",
        "        if self.use_mock:\n",
        "            return self._create_mock_audio(script, output_path)\n",
        "        \n",
        "        try:\n",
        "            # Convert to SSML\n",
        "            ssml_text = self.script_to_ssml(script)\n",
        "            \n",
        "            # Synthesize speech\n",
        "            synthesis_input = texttospeech.SynthesisInput(ssml=ssml_text)\n",
        "            \n",
        "            response = self.client.synthesize_speech(\n",
        "                input=synthesis_input,\n",
        "                voice=self.voice_config,\n",
        "                audio_config=self.audio_config\n",
        "            )\n",
        "            \n",
        "            # Save audio file\n",
        "            with open(output_path, \"wb\") as out:\n",
        "                out.write(response.audio_content)\n",
        "            \n",
        "            print(f\"âœ… Audio synthesized: {output_path}\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Speech synthesis failed: {e}. Creating mock audio.\")\n",
        "            return self._create_mock_audio(script, output_path)\n",
        "    \n",
        "    def _create_mock_audio(self, script: PodcastScriptStructure, output_path: Path) -> bool:\n",
        "        \"\"\"Create mock audio file for testing\"\"\"\n",
        "        try:\n",
        "            # Create a simple tone as placeholder\n",
        "            # Duration based on script length\n",
        "            script_text = f\"{script.introduction} {script.research_context} {script.methods_summary} {' '.join(script.key_findings)} {script.institute_connection} {script.implications_and_significance} {script.conclusion}\"\n",
        "            \n",
        "            # Estimate duration (assume ~150 words per minute)\n",
        "            word_count = len(script_text.split())\n",
        "            duration_minutes = max(2, word_count / 150)  # At least 2 minutes\n",
        "            duration_ms = int(duration_minutes * 60 * 1000)\n",
        "            \n",
        "            # Generate a simple tone\n",
        "            tone = AudioSegment.silent(duration=duration_ms)\n",
        "            \n",
        "            # Add some variation (simple sine wave)\n",
        "            from math import sin, pi\n",
        "            import array\n",
        "            \n",
        "            sample_rate = 44100\n",
        "            samples = []\n",
        "            \n",
        "            for i in range(int(sample_rate * duration_minutes * 60)):\n",
        "                # Mix of frequencies to simulate speech\n",
        "                t = i / sample_rate\n",
        "                sample = int(32767 * 0.1 * (sin(2 * pi * 200 * t) + 0.5 * sin(2 * pi * 400 * t)))\n",
        "                samples.append(sample)\n",
        "            \n",
        "            # Convert to audio\n",
        "            audio_array = array.array('h', samples)\n",
        "            audio = AudioSegment(\n",
        "                audio_array.tobytes(),\n",
        "                frame_rate=sample_rate,\n",
        "                sample_width=2,\n",
        "                channels=1\n",
        "            )\n",
        "            \n",
        "            # Export as MP3\n",
        "            audio.export(output_path, format=\"mp3\")\n",
        "            \n",
        "            print(f\"âœ… Mock audio created: {output_path} ({duration_minutes:.1f} min)\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Mock audio creation failed: {e}\")\n",
        "            return False\n",
        "\n",
        "# Initialize voice synthesizer\n",
        "voice_synthesizer = VoiceSynthesizer(tts_client)\n",
        "\n",
        "print(f\"âœ… Voice synthesizer initialized\")\n",
        "print(f\"   Mode: {'ðŸŽ™ï¸ Google TTS' if not voice_synthesizer.use_mock else 'ðŸ”§ Mock audio'}\")\n",
        "print(f\"   Voice: en-US-Studio-M (Professional male)\")\n",
        "print(f\"   Output: High-quality MP3 audio files\")"
      ]
    },
    {
      "id": "VSC-7. COMPLETE PIPELINE",
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. COMPLETE PODCAST GENERATION PIPELINE\n",
        "print(\"ðŸŽ¯ ASSEMBLING COMPLETE PIPELINE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "class CompletePodcastPipeline:\n",
        "    \"\"\"Complete pipeline for generating podcasts from similarity matches\"\"\"\n",
        "    \n",
        "    def __init__(self, script_generator: PodcastScriptGenerator, voice_synthesizer: VoiceSynthesizer):\n",
        "        self.script_generator = script_generator\n",
        "        self.voice_synthesizer = voice_synthesizer\n",
        "        self.generated_podcasts = []\n",
        "    \n",
        "    async def generate_podcast_episode(self, similarity_match: Dict, episode_number: int) -> Dict:\n",
        "        \"\"\"Generate complete podcast episode from similarity match\"\"\"\n",
        "        \n",
        "        print(f\"\\nðŸŽ™ï¸ Generating Podcast Episode {episode_number}\")\n",
        "        print(\"=\" * 40)\n",
        "        \n",
        "        episode_data = {\n",
        "            'episode_number': episode_number,\n",
        "            'similarity_match': similarity_match,\n",
        "            'generation_timestamp': datetime.now().isoformat(),\n",
        "            'status': 'processing',\n",
        "            'files_generated': {},\n",
        "            'metadata': {}\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            # Step 1: Generate structured script\n",
        "            print(\"ðŸ“ Step 1: Generating structured script...\")\n",
        "            script = await self.script_generator.generate_script(similarity_match)\n",
        "            episode_data['script'] = script.model_dump()\n",
        "            \n",
        "            print(f\"   âœ… Script generated: '{script.podcast_title}'\")\n",
        "            print(f\"   ðŸ“Š Sections: {len(script.key_findings)} findings, {len(script.model_dump_json().split())} words\")\n",
        "            \n",
        "            # Step 2: Save script files\n",
        "            print(\"ðŸ’¾ Step 2: Saving script files...\")\n",
        "            \n",
        "            # Create episode directory\n",
        "            episode_dir = podcast_output_dir / f\"episode_{episode_number:03d}\"\n",
        "            episode_dir.mkdir(exist_ok=True)\n",
        "            \n",
        "            # Save structured script as JSON\n",
        "            script_json_path = episode_dir / \"script_structured.json\"\n",
        "            with open(script_json_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(script.model_dump(), f, indent=2, ensure_ascii=False)\n",
        "            \n",
        "            # Save readable script as markdown\n",
        "            script_md_path = episode_dir / \"script_readable.md\"\n",
        "            readable_script = self._format_script_for_reading(script)\n",
        "            with open(script_md_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(readable_script)\n",
        "            \n",
        "            episode_data['files_generated']['script_json'] = str(script_json_path)\n",
        "            episode_data['files_generated']['script_markdown'] = str(script_md_path)\n",
        "            \n",
        "            print(f\"   âœ… Scripts saved to: {episode_dir}\")\n",
        "            \n",
        "            # Step 3: Generate audio\n",
        "            print(\"ðŸŽ™ï¸ Step 3: Synthesizing speech...\")\n",
        "            \n",
        "            audio_path = episode_dir / \"podcast_audio.mp3\"\n",
        "            audio_success = await self.voice_synthesizer.synthesize_speech(script, audio_path)\n",
        "            \n",
        "            if audio_success:\n",
        "                episode_data['files_generated']['audio_mp3'] = str(audio_path)\n",
        "                \n",
        "                # Get audio duration if possible\n",
        "                try:\n",
        "                    audio = AudioSegment.from_mp3(audio_path)\n",
        "                    duration_minutes = len(audio) / 60000\n",
        "                    episode_data['metadata']['duration_minutes'] = round(duration_minutes, 2)\n",
        "                    print(f\"   âœ… Audio generated: {duration_minutes:.1f} minutes\")\n",
        "                except:\n",
        "                    print(f\"   âœ… Audio file created: {audio_path}\")\n",
        "            \n",
        "            # Step 4: Generate episode metadata\n",
        "            print(\"ðŸ“‹ Step 4: Creating episode metadata...\")\n",
        "            \n",
        "            metadata = {\n",
        "                'episode_number': episode_number,\n",
        "                'title': script.podcast_title,\n",
        "                'description': script.introduction[:200] + \"...\",\n",
        "                'recent_article': {\n",
        "                    'title': similarity_match['recent_pubmed_article']['title'],\n",
        "                    'journal': similarity_match['recent_pubmed_article']['journal'],\n",
        "                    'pmid': similarity_match['recent_pubmed_article']['pmid']\n",
        "                },\n",
        "                'institute_connection': {\n",
        "                    'title': similarity_match['matched_institute_article']['title'],\n",
        "                    'journal': similarity_match['matched_institute_article']['journal'],\n",
        "                    'year': similarity_match['matched_institute_article']['year']\n",
        "                },\n",
        "                'similarity_score': similarity_match['similarity_score'],\n",
        "                'generation_date': datetime.now().isoformat(),\n",
        "                'files': episode_data['files_generated']\n",
        "            }\n",
        "            \n",
        "            # Save episode metadata\n",
        "            metadata_path = episode_dir / \"episode_metadata.json\"\n",
        "            with open(metadata_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
        "            \n",
        "            episode_data['files_generated']['metadata'] = str(metadata_path)\n",
        "            episode_data['metadata'].update(metadata)\n",
        "            \n",
        "            print(f\"   âœ… Metadata saved: {metadata_path}\")\n",
        "            \n",
        "            episode_data['status'] = 'completed'\n",
        "            \n",
        "            print(f\"\\nðŸŽ‰ Episode {episode_number} completed successfully!\")\n",
        "            print(f\"   ðŸ“ Output directory: {episode_dir}\")\n",
        "            print(f\"   ðŸ“„ Files: {len(episode_data['files_generated'])} generated\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            episode_data['status'] = 'error'\n",
        "            episode_data['error'] = str(e)\n",
        "            print(f\"âŒ Episode {episode_number} generation failed: {e}\")\n",
        "        \n",
        "        return episode_data\n",
        "    \n",
        "    def _format_script_for_reading(self, script: PodcastScriptStructure) -> str:\n",
        "        \"\"\"Format structured script for human reading\"\"\"\n",
        "        \n",
        "        return f\"\"\"# {script.podcast_title}\n",
        "\n",
        "## Introduction\n",
        "{script.introduction}\n",
        "\n",
        "## Research Context\n",
        "{script.research_context}\n",
        "\n",
        "## Methods Summary\n",
        "{script.methods_summary}\n",
        "\n",
        "## Key Findings\n",
        "{chr(10).join(f\"{i+1}. {finding}\" for i, finding in enumerate(script.key_findings))}\n",
        "\n",
        "## Institute Connection\n",
        "{script.institute_connection}\n",
        "\n",
        "## Implications and Significance\n",
        "{script.implications_and_significance}\n",
        "\n",
        "## Conclusion\n",
        "{script.conclusion}\n",
        "\n",
        "---\n",
        "*Generated by UBMI-IFC Podcast Pipeline*\n",
        "\"\"\"\n",
        "    \n",
        "    async def generate_all_episodes(self, max_episodes: int = None) -> List[Dict]:\n",
        "        \"\"\"Generate podcast episodes for all similarity matches\"\"\"\n",
        "        \n",
        "        matches_to_process = similarity_data['top_matches']\n",
        "        if max_episodes:\n",
        "            matches_to_process = matches_to_process[:max_episodes]\n",
        "        \n",
        "        print(f\"\\nðŸš€ GENERATING {len(matches_to_process)} PODCAST EPISODES\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        episodes = []\n",
        "        \n",
        "        for i, match in enumerate(matches_to_process, 1):\n",
        "            episode_data = await self.generate_podcast_episode(match, i)\n",
        "            episodes.append(episode_data)\n",
        "            self.generated_podcasts.append(episode_data)\n",
        "        \n",
        "        # Generate series metadata\n",
        "        series_metadata = {\n",
        "            'series_title': 'UBMI-IFC Research Frontiers',\n",
        "            'description': 'Exploring cutting-edge research and its connections to institute work',\n",
        "            'total_episodes': len(episodes),\n",
        "            'generation_date': datetime.now().isoformat(),\n",
        "            'episodes': [\n",
        "                {\n",
        "                    'episode_number': ep['episode_number'],\n",
        "                    'title': ep.get('metadata', {}).get('title', 'Unknown'),\n",
        "                    'status': ep['status'],\n",
        "                    'similarity_score': ep.get('metadata', {}).get('similarity_score', 0)\n",
        "                } for ep in episodes\n",
        "            ]\n",
        "        }\n",
        "        \n",
        "        # Save series metadata\n",
        "        series_metadata_path = podcast_output_dir / \"series_metadata.json\"\n",
        "        with open(series_metadata_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(series_metadata, f, indent=2, ensure_ascii=False)\n",
        "        \n",
        "        print(f\"\\nðŸ“Š PIPELINE SUMMARY\")\n",
        "        print(\"=\" * 30)\n",
        "        successful_episodes = sum(1 for ep in episodes if ep['status'] == 'completed')\n",
        "        print(f\"âœ… Episodes completed: {successful_episodes}/{len(episodes)}\")\n",
        "        print(f\"ðŸ“ Output directory: {podcast_output_dir}\")\n",
        "        print(f\"ðŸ’¾ Series metadata: {series_metadata_path}\")\n",
        "        \n",
        "        return episodes\n",
        "\n",
        "# Initialize complete pipeline\n",
        "complete_pipeline = CompletePodcastPipeline(script_generator, voice_synthesizer)\n",
        "\n",
        "print(\"âœ… Complete podcast pipeline assembled\")\n",
        "print(f\"   Components: Script generation + Voice synthesis\")\n",
        "print(f\"   Output: Complete podcast episodes with audio\")\n",
        "print(f\"   Ready to process {len(similarity_data['top_matches'])} similarity matches\")"
      ]
    },
    {
      "id": "VSC-8. GENERATE PODCASTS",
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. GENERATE PODCAST EPISODES\n",
        "print(\"ðŸŽ¬ STARTING PODCAST GENERATION\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Generate podcasts (limit to first 3 for testing)\n",
        "max_episodes_to_generate = min(3, len(similarity_data['top_matches']))\n",
        "\n",
        "print(f\"Generating {max_episodes_to_generate} podcast episodes...\")\n",
        "print(f\"This may take several minutes per episode.\")\n",
        "\n",
        "# Run the complete pipeline\n",
        "generated_episodes = await complete_pipeline.generate_all_episodes(max_episodes=max_episodes_to_generate)\n",
        "\n",
        "# Display results\n",
        "print(f\"\\nðŸŽ‰ PODCAST GENERATION COMPLETED!\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for episode in generated_episodes:\n",
        "    print(f\"\\nðŸ“» Episode {episode['episode_number']}:\")\n",
        "    if episode['status'] == 'completed':\n",
        "        print(f\"   âœ… Status: {episode['status']}\")\n",
        "        print(f\"   ðŸŽµ Title: {episode.get('metadata', {}).get('title', 'Unknown')[:60]}...\")\n",
        "        print(f\"   â±ï¸ Duration: {episode.get('metadata', {}).get('duration_minutes', 'Unknown')} minutes\")\n",
        "        print(f\"   ðŸ“ Files: {len(episode.get('files_generated', {}))} generated\")\n",
        "        print(f\"   ðŸ“Š Similarity: {episode.get('metadata', {}).get('similarity_score', 0):.3f}\")\n",
        "    else:\n",
        "        print(f\"   âŒ Status: {episode['status']}\")\n",
        "        if 'error' in episode:\n",
        "            print(f\"   Error: {episode['error']}\")\n",
        "\n",
        "# Summary statistics\n",
        "successful_count = sum(1 for ep in generated_episodes if ep['status'] == 'completed')\n",
        "total_duration = sum(ep.get('metadata', {}).get('duration_minutes', 0) for ep in generated_episodes if ep['status'] == 'completed')\n",
        "\n",
        "print(f\"\\nðŸ“ˆ GENERATION STATISTICS:\")\n",
        "print(f\"   Success rate: {successful_count}/{len(generated_episodes)} ({successful_count/len(generated_episodes):.1%})\")\n",
        "print(f\"   Total audio: {total_duration:.1f} minutes\")\n",
        "print(f\"   Output location: {podcast_output_dir}\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ Next steps:\")\n",
        "print(f\"   1. Review generated scripts in episode directories\")\n",
        "print(f\"   2. Listen to audio files for quality assessment\")\n",
        "print(f\"   3. Adjust voice parameters if needed\")\n",
        "print(f\"   4. Set up automated scheduling for regular generation\")"
      ]
    },
    {
      "id": "VSC-9. ANALYSIS AND EXPORT",
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. ANALYSIS AND EXPORT\n",
        "print(\"ðŸ“Š ANALYZING GENERATED PODCASTS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Analyze the generated podcasts\n",
        "def analyze_podcast_quality(episodes: List[Dict]) -> Dict:\n",
        "    \"\"\"Analyze quality metrics of generated podcasts\"\"\"\n",
        "    \n",
        "    analysis = {\n",
        "        'total_episodes': len(episodes),\n",
        "        'successful_episodes': 0,\n",
        "        'failed_episodes': 0,\n",
        "        'total_duration_minutes': 0,\n",
        "        'average_similarity_score': 0,\n",
        "        'script_metrics': {\n",
        "            'average_word_count': 0,\n",
        "            'average_findings_count': 0\n",
        "        },\n",
        "        'quality_scores': [],\n",
        "        'research_fields': {}\n",
        "    }\n",
        "    \n",
        "    successful_episodes = [ep for ep in episodes if ep['status'] == 'completed']\n",
        "    analysis['successful_episodes'] = len(successful_episodes)\n",
        "    analysis['failed_episodes'] = len(episodes) - len(successful_episodes)\n",
        "    \n",
        "    if successful_episodes:\n",
        "        # Duration analysis\n",
        "        durations = [ep.get('metadata', {}).get('duration_minutes', 0) for ep in successful_episodes]\n",
        "        analysis['total_duration_minutes'] = sum(durations)\n",
        "        analysis['average_duration_minutes'] = np.mean(durations)\n",
        "        \n",
        "        # Similarity score analysis\n",
        "        similarity_scores = [ep.get('metadata', {}).get('similarity_score', 0) for ep in successful_episodes]\n",
        "        analysis['average_similarity_score'] = np.mean(similarity_scores)\n",
        "        analysis['similarity_score_range'] = [min(similarity_scores), max(similarity_scores)]\n",
        "        \n",
        "        # Script analysis\n",
        "        word_counts = []\n",
        "        findings_counts = []\n",
        "        \n",
        "        for ep in successful_episodes:\n",
        "            script_data = ep.get('script', {})\n",
        "            if script_data:\n",
        "                # Count words in all script sections\n",
        "                all_text = ' '.join([\n",
        "                    script_data.get('introduction', ''),\n",
        "                    script_data.get('research_context', ''),\n",
        "                    script_data.get('methods_summary', ''),\n",
        "                    ' '.join(script_data.get('key_findings', [])),\n",
        "                    script_data.get('institute_connection', ''),\n",
        "                    script_data.get('implications_and_significance', ''),\n",
        "                    script_data.get('conclusion', '')\n",
        "                ])\n",
        "                word_counts.append(len(all_text.split()))\n",
        "                findings_counts.append(len(script_data.get('key_findings', [])))\n",
        "        \n",
        "        if word_counts:\n",
        "            analysis['script_metrics']['average_word_count'] = int(np.mean(word_counts))\n",
        "            analysis['script_metrics']['word_count_range'] = [min(word_counts), max(word_counts)]\n",
        "        \n",
        "        if findings_counts:\n",
        "            analysis['script_metrics']['average_findings_count'] = np.mean(findings_counts)\n",
        "        \n",
        "        # Research field analysis\n",
        "        for ep in successful_episodes:\n",
        "            title = ep.get('metadata', {}).get('recent_article', {}).get('title', '').lower()\n",
        "            \n",
        "            # Simple field detection\n",
        "            if any(word in title for word in ['neural', 'brain', 'neuron']):\n",
        "                field = 'Neuroscience'\n",
        "            elif any(word in title for word in ['cancer', 'tumor', 'oncology']):\n",
        "                field = 'Oncology'\n",
        "            elif any(word in title for word in ['immune', 'antibody', 'vaccine']):\n",
        "                field = 'Immunology'\n",
        "            elif any(word in title for word in ['gene', 'genetic', 'dna']):\n",
        "                field = 'Genetics'\n",
        "            elif any(word in title for word in ['heart', 'cardiac', 'cardiovascular']):\n",
        "                field = 'Cardiology'\n",
        "            else:\n",
        "                field = 'Other'\n",
        "            \n",
        "            analysis['research_fields'][field] = analysis['research_fields'].get(field, 0) + 1\n",
        "    \n",
        "    return analysis\n",
        "\n",
        "# Perform analysis\n",
        "podcast_analysis = analyze_podcast_quality(generated_episodes)\n",
        "\n",
        "# Display analysis results\n",
        "print(f\"\\nðŸ“ˆ PODCAST QUALITY ANALYSIS:\")\n",
        "print(f\"   Episodes generated: {podcast_analysis['total_episodes']}\")\n",
        "print(f\"   Success rate: {podcast_analysis['successful_episodes']}/{podcast_analysis['total_episodes']} ({podcast_analysis['successful_episodes']/podcast_analysis['total_episodes']:.1%})\")\n",
        "\n",
        "if podcast_analysis['successful_episodes'] > 0:\n",
        "    print(f\"\\nâ±ï¸ DURATION METRICS:\")\n",
        "    print(f\"   Total content: {podcast_analysis['total_duration_minutes']:.1f} minutes\")\n",
        "    print(f\"   Average episode: {podcast_analysis.get('average_duration_minutes', 0):.1f} minutes\")\n",
        "    \n",
        "    print(f\"\\nðŸ“Š SIMILARITY METRICS:\")\n",
        "    print(f\"   Average similarity: {podcast_analysis['average_similarity_score']:.3f}\")\n",
        "    print(f\"   Similarity range: {podcast_analysis['similarity_score_range'][0]:.3f} - {podcast_analysis['similarity_score_range'][1]:.3f}\")\n",
        "    \n",
        "    print(f\"\\nðŸ“ SCRIPT METRICS:\")\n",
        "    print(f\"   Average words: {podcast_analysis['script_metrics']['average_word_count']}\")\n",
        "    print(f\"   Average findings: {podcast_analysis['script_metrics']['average_findings_count']:.1f}\")\n",
        "    \n",
        "    if podcast_analysis['research_fields']:\n",
        "        print(f\"\\nðŸ”¬ RESEARCH FIELDS:\")\n",
        "        for field, count in podcast_analysis['research_fields'].items():\n",
        "            print(f\"   {field}: {count} episode(s)\")\n",
        "\n",
        "# Save analysis results\n",
        "analysis_path = podcast_output_dir / \"podcast_analysis.json\"\n",
        "with open(analysis_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(podcast_analysis, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "print(f\"\\nðŸ’¾ Analysis saved to: {analysis_path}\")\n",
        "\n",
        "# Generate RSS feed for podcast distribution\n",
        "def generate_rss_feed(episodes: List[Dict], output_path: Path):\n",
        "    \"\"\"Generate RSS feed for podcast distribution\"\"\"\n",
        "    \n",
        "    from xml.etree.ElementTree import Element, SubElement, tostring\n",
        "    from xml.dom import minidom\n",
        "    \n",
        "    # Create RSS structure\n",
        "    rss = Element('rss', version='2.0')\n",
        "    rss.set('xmlns:itunes', 'http://www.itunes.com/dtds/podcast-1.0.dtd')\n",
        "    \n",
        "    channel = SubElement(rss, 'channel')\n",
        "    \n",
        "    # Channel information\n",
        "    SubElement(channel, 'title').text = 'UBMI-IFC Research Frontiers'\n",
        "    SubElement(channel, 'description').text = 'Exploring cutting-edge research and its connections to institute work'\n",
        "    SubElement(channel, 'language').text = 'en-us'\n",
        "    SubElement(channel, 'category').text = 'Science'\n",
        "    SubElement(channel, 'pubDate').text = datetime.now().strftime('%a, %d %b %Y %H:%M:%S %z')\n",
        "    \n",
        "    # Add episodes\n",
        "    for episode in episodes:\n",
        "        if episode['status'] == 'completed':\n",
        "            item = SubElement(channel, 'item')\n",
        "            \n",
        "            metadata = episode.get('metadata', {})\n",
        "            \n",
        "            SubElement(item, 'title').text = metadata.get('title', f\"Episode {episode['episode_number']}\")\n",
        "            SubElement(item, 'description').text = metadata.get('description', 'Research podcast episode')\n",
        "            SubElement(item, 'pubDate').text = datetime.fromisoformat(metadata.get('generation_date', datetime.now().isoformat())).strftime('%a, %d %b %Y %H:%M:%S %z')\n",
        "            \n",
        "            # Add audio enclosure if available\n",
        "            audio_file = episode.get('files_generated', {}).get('audio_mp3')\n",
        "            if audio_file and Path(audio_file).exists():\n",
        "                file_size = Path(audio_file).stat().st_size\n",
        "                enclosure = SubElement(item, 'enclosure')\n",
        "                enclosure.set('url', f\"file://{audio_file}\")  # In production, use actual URL\n",
        "                enclosure.set('length', str(file_size))\n",
        "                enclosure.set('type', 'audio/mpeg')\n",
        "    \n",
        "    # Pretty print XML\n",
        "    rough_string = tostring(rss, 'unicode')\n",
        "    reparsed = minidom.parseString(rough_string)\n",
        "    \n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(reparsed.toprettyxml(indent=\"  \"))\n",
        "\n",
        "# Generate RSS feed\n",
        "rss_path = podcast_output_dir / \"podcast_feed.xml\"\n",
        "generate_rss_feed(generated_episodes, rss_path)\n",
        "\n",
        "print(f\"\\nðŸ“¡ RSS feed generated: {rss_path}\")\n",
        "print(f\"\\nðŸŽ‰ PODCAST GENERATION PIPELINE COMPLETE!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"ðŸ“ All outputs saved to: {podcast_output_dir}\")\n",
        "print(f\"ðŸ“Š Analysis available in: podcast_analysis.json\")\n",
        "print(f\"ðŸ“¡ RSS feed ready: podcast_feed.xml\")\n",
        "print(f\"\\nðŸš€ Your podcast is ready for distribution!\")"
      ]
    }
  ]
}