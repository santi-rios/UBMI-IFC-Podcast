{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ef91a1",
   "metadata": {},
   "source": [
    "# PubMed Search Testing Notebook\n",
    "\n",
    "This notebook tests the PubMed search and article retrieval functionality.\n",
    "\n",
    "## Overview\n",
    "- Test PubMed API integration\n",
    "- Search for recent articles\n",
    "- Retrieve article details\n",
    "- Validate data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01611bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f64ea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: /home/santi/Projects/UBMI-IFC-Podcast/notebooks\n",
      "Source directory: /home/santi/Projects/UBMI-IFC-Podcast/src\n",
      "Source exists: True\n",
      "✅ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Import our modules - Fixed import paths\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to path for imports\n",
    "notebook_dir = Path().resolve()\n",
    "src_dir = notebook_dir.parent / \"src\"\n",
    "sys.path.insert(0, str(src_dir))\n",
    "\n",
    "print(f\"Notebook directory: {notebook_dir}\")\n",
    "print(f\"Source directory: {src_dir}\")\n",
    "print(f\"Source exists: {src_dir.exists()}\")\n",
    "\n",
    "# Now import our modules\n",
    "from pubmed.searcher import PubMedSearcher\n",
    "from utils.config import load_config\n",
    "from utils.logger import setup_logger, get_logger\n",
    "\n",
    "# Setup logging\n",
    "setup_logger(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "print(\"✅ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5573c",
   "metadata": {},
   "source": [
    "## 1. Configure PubMed Access\n",
    "\n",
    "**Important**: You need to set your email in the config for PubMed API access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74df809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PubMed configuration:\n",
      "Email: santiago_gr@ciencias.unam.mx\n",
      "Base URL: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\n",
      "Rate limit: 0.34s\n",
      "Max articles per week: 1000\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config = load_config()\n",
    "print(\"PubMed configuration:\")\n",
    "print(f\"Email: {config['pubmed']['email']}\")\n",
    "print(f\"Base URL: {config['pubmed']['base_url']}\")\n",
    "print(f\"Rate limit: {config['pubmed']['rate_limit_delay']}s\")\n",
    "print(f\"Max articles per week: {config['pubmed']['max_articles_per_week']}\")\n",
    "\n",
    "if config['pubmed']['email'] == 'your-email@example.com':\n",
    "    print(\"\\n⚠️  WARNING: Please update your email in config/config.yaml or .env file\")\n",
    "    print(\"NCBI requires a valid email for API access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a63f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PubMed searcher initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize searcher\n",
    "searcher = PubMedSearcher(config)\n",
    "print(\"PubMed searcher initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c696de",
   "metadata": {},
   "source": [
    "## 2. Test Basic Search\n",
    "\n",
    "Start with a simple search to test the API connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "261d6cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:56:36\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mSearching PubMed with query: \"neuroscience\"[Abstract] OR \"physiology\"[Abstract]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing search with terms: ['neuroscience', 'physiology']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:56:47\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mFound 10 articles\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Search successful! Found 10 articles\n",
      "Sample PMIDs: ['18558853', '18284371', '15664172', '32697748', '33848482']\n"
     ]
    }
   ],
   "source": [
    "# Test basic search with neuroscience terms\n",
    "import asyncio\n",
    "\n",
    "async def test_basic_search():\n",
    "    test_terms = [\"neuroscience\", \"physiology\"]\n",
    "    print(f\"Testing search with terms: {test_terms}\")\n",
    "\n",
    "    try:\n",
    "        pmids = await searcher.search_recent_articles(\n",
    "            query_terms=test_terms,\n",
    "            days_back=7,\n",
    "            max_results=10  # Small number for testing\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Search successful! Found {len(pmids)} articles\")\n",
    "        print(f\"Sample PMIDs: {pmids[:5]}\")\n",
    "        return pmids\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Search failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# Run the async function\n",
    "pmids = await test_basic_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12717586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:57:54\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msimple_search_override\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mSimple search query: \"neuroscience\"[Title/Abstract]\u001b[0m\n",
      "\u001b[32m2025-09-17 15:57:55\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msimple_search_override\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mFound 5 articles\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple search found 5 PMIDs: ['30085354', '29723499', '30522733', '37736162', '34381347']\n"
     ]
    }
   ],
   "source": [
    "# Test with a simpler query to isolate the issue\n",
    "import aiohttp\n",
    "\n",
    "async def test_simple_search():\n",
    "    \"\"\"Test with a very simple query without date filters\"\"\"\n",
    "    \n",
    "    # Override the searcher method temporarily for testing\n",
    "    original_search = searcher.search_recent_articles\n",
    "    \n",
    "    async def simple_search_override(query_terms=None, days_back=7, max_results=1000):\n",
    "        \"\"\"Simplified search without complex date filters\"\"\"\n",
    "        \n",
    "        # Simple query without date filters\n",
    "        if query_terms:\n",
    "            query = \" OR \".join([f'\"{term}\"[Title/Abstract]' for term in query_terms])\n",
    "        else:\n",
    "            query = \"neuroscience\"\n",
    "        \n",
    "        searcher.logger.info(f\"Simple search query: {query}\")\n",
    "        \n",
    "        # Parameters for esearch\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'term': query,\n",
    "            'retmax': max_results,\n",
    "            'retmode': 'xml',\n",
    "            'tool': 'ubmi-ifc-podcast',\n",
    "            'email': searcher.email,\n",
    "            'sort': 'relevance'\n",
    "        }\n",
    "        \n",
    "        url = f\"{searcher.base_url}esearch.fcgi\"\n",
    "        \n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            try:\n",
    "                async with session.get(url, params=params) as response:\n",
    "                    if response.status == 200:\n",
    "                        xml_content = await response.text()\n",
    "                        pmids = searcher._parse_search_results(xml_content)\n",
    "                        searcher.logger.info(f\"Found {len(pmids)} articles\")\n",
    "                        return pmids[:max_results]\n",
    "                    else:\n",
    "                        searcher.logger.error(f\"Search failed with status {response.status}\")\n",
    "                        error_content = await response.text()\n",
    "                        searcher.logger.error(f\"Error content: {error_content}\")\n",
    "                        return []\n",
    "            except Exception as e:\n",
    "                searcher.logger.error(f\"Error in simple search: {str(e)}\")\n",
    "                return []\n",
    "    \n",
    "    # Temporarily replace the method\n",
    "    searcher.search_recent_articles = simple_search_override\n",
    "    \n",
    "    try:\n",
    "        pmids = await searcher.search_recent_articles(\n",
    "            query_terms=[\"neuroscience\"],\n",
    "            max_results=5\n",
    "        )\n",
    "        print(f\"Simple search found {len(pmids)} PMIDs: {pmids}\")\n",
    "        return pmids\n",
    "    finally:\n",
    "        # Restore original method\n",
    "        searcher.search_recent_articles = original_search\n",
    "\n",
    "# Test simple search\n",
    "simple_pmids = await test_simple_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f7525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing direct PubMed API call...\n",
      "URL: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\n",
      "Params: {'db': 'pubmed', 'term': 'neuroscience[Title]', 'retmax': 5, 'retmode': 'xml', 'tool': 'ifc-podcast-generator', 'email': 'test@example.com'}\n",
      "Status: 200\n",
      "Headers: {'Date': 'Wed, 17 Sep 2025 21:58:00 GMT', 'Server': 'Finatra', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'Content-Security-Policy': 'upgrade-insecure-requests', 'Referrer-Policy': 'origin-when-cross-origin', 'NCBI-SID': 'E34FD6E3A8540DBB_EB2FSID', 'NCBI-PHID': '1D340F5DAC9273150000169538C3E658.1.1.m_1', 'Content-Type': 'text/xml; charset=UTF-8', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'X-RateLimit-Limit': '3', 'X-RateLimit-Remaining': '2', 'Access-Control-Allow-Origin': '*', 'Access-Control-Expose-Headers': 'X-RateLimit-Limit,X-RateLimit-Remaining', 'Set-Cookie': 'ncbi_sid=E34FD6E3A8540DBB_EB2FSID; domain=.nih.gov; path=/; expires=Thu, 17 Sep 2026 21:58:01 GMT', 'X-UA-Compatible': 'IE=Edge', 'X-XSS-Protection': '1; mode=block', 'Transfer-Encoding': 'chunked'}\n",
      "Response length: 447\n",
      "Response preview: <?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
      "<!DOCTYPE eSearchResult PUBLIC \"-//NLM//DTD esearch 20060628//EN\" \"https://eutils.ncbi.nlm.nih.gov/eutils/dtd/20060628/esearch.dtd\">\n",
      "<eSearchResult><Count>9614</Count><RetMax>5</RetMax><RetStart>0</RetStart><IdList>\n",
      "<Id>40947286</Id>\n",
      "<Id>40946168</Id>\n",
      "<Id>40940411</Id>\n",
      "<Id>40939870</Id>\n",
      "<Id>40938441</Id>\n",
      "</IdList><TranslationSet/><QueryTranslation>\"neuroscience\"[Title]</QueryTranslation></eSearchResult>\n",
      "...\n",
      "Found PMIDs: ['40947286', '40946168', '40940411', '40939870', '40938441']\n"
     ]
    }
   ],
   "source": [
    "# Test PubMed API directly with a temporary valid email\n",
    "import aiohttp\n",
    "\n",
    "async def test_pubmed_api_direct():\n",
    "    \"\"\"Test PubMed API directly to diagnose issues\"\"\"\n",
    "    \n",
    "    # Use a simple test email for API testing\n",
    "    test_email = \"test@example.com\"  # You should replace this with your actual email\n",
    "    \n",
    "    # Simple search query\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': 'neuroscience[Title]',\n",
    "        'retmax': 5,\n",
    "        'retmode': 'xml',\n",
    "        'tool': 'ifc-podcast-generator',\n",
    "        'email': test_email\n",
    "    }\n",
    "    \n",
    "    print(f\"Testing direct PubMed API call...\")\n",
    "    print(f\"URL: {base_url}\")\n",
    "    print(f\"Params: {params}\")\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.get(base_url, params=params) as response:\n",
    "                print(f\"Status: {response.status}\")\n",
    "                print(f\"Headers: {dict(response.headers)}\")\n",
    "                \n",
    "                if response.status == 200:\n",
    "                    content = await response.text()\n",
    "                    print(f\"Response length: {len(content)}\")\n",
    "                    print(f\"Response preview: {content[:500]}...\")\n",
    "                    \n",
    "                    # Try to parse XML\n",
    "                    from xml.etree import ElementTree as ET\n",
    "                    try:\n",
    "                        root = ET.fromstring(content)\n",
    "                        id_list = root.find('.//IdList')\n",
    "                        if id_list is not None:\n",
    "                            pmids = [id_elem.text for id_elem in id_list.findall('Id')]\n",
    "                            print(f\"Found PMIDs: {pmids}\")\n",
    "                        else:\n",
    "                            print(\"No IdList found in response\")\n",
    "                    except ET.ParseError as e:\n",
    "                        print(f\"XML parse error: {e}\")\n",
    "                        \n",
    "                else:\n",
    "                    error_content = await response.text()\n",
    "                    print(f\"Error response: {error_content}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "\n",
    "# Run direct API test\n",
    "await test_pubmed_api_direct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b28f7",
   "metadata": {},
   "source": [
    "## 3. Test Article Detail Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c9780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching details for 10 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:58:13\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36mfetch_article_details\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1mRetrieved details for 10 articles\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Retrieved details for 10 articles\n",
      "\n",
      "📄 Sample article:\n",
      "PMID: 18558853\n",
      "Title: Descending pathways in motor control.\n",
      "Authors: Roger N Lemon\n",
      "Journal: Annual review of neuroscience\n",
      "Publication Date: 2008\n",
      "DOI: 10.1146/annurev.neuro.31.060407.125547\n",
      "Abstract length: 1036 characters\n",
      "MeSH terms: ['Animals', 'Biological Evolution', 'Brain', 'Efferent Pathways', 'Humans']\n",
      "\n",
      "Abstract preview: Each of the descending pathways involved in motor control has a number of anatomical, molecular, pharmacological, and neuroinformatic characteristics. They are differentially involved in motor control...\n"
     ]
    }
   ],
   "source": [
    "# Test fetching details for found articles\n",
    "async def test_article_details():\n",
    "    if pmids:\n",
    "        print(f\"Fetching details for {len(pmids)} articles...\")\n",
    "        \n",
    "        try:\n",
    "            articles = await searcher.fetch_article_details(pmids)\n",
    "            print(f\"✅ Retrieved details for {len(articles)} articles\")\n",
    "            \n",
    "            if articles:\n",
    "                sample = articles[0]\n",
    "                print(\"\\n📄 Sample article:\")\n",
    "                print(f\"PMID: {sample.pmid}\")\n",
    "                print(f\"Title: {sample.title}\")\n",
    "                print(f\"Authors: {', '.join(sample.authors[:3]) if sample.authors else 'No authors'}\")\n",
    "                print(f\"Journal: {sample.journal}\")\n",
    "                print(f\"Publication Date: {sample.publication_date}\")\n",
    "                print(f\"DOI: {sample.doi}\")\n",
    "                print(f\"Abstract length: {len(sample.abstract) if sample.abstract else 0} characters\")\n",
    "                print(f\"MeSH terms: {sample.mesh_terms[:5] if sample.mesh_terms else 'None'}\")\n",
    "                \n",
    "                if sample.abstract:\n",
    "                    print(f\"\\nAbstract preview: {sample.abstract[:200]}...\")\n",
    "            \n",
    "            return articles\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Detail retrieval failed: {e}\")\n",
    "            return []\n",
    "    else:\n",
    "        print(\"⏭️  Skipping detail retrieval (no PMIDs found)\")\n",
    "        return []\n",
    "\n",
    "# Run the async function\n",
    "articles = await test_article_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fdf9a4",
   "metadata": {},
   "source": [
    "## 4. Test Different Search Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fdb83b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:58:21\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mSearching PubMed with query: (humans[MeSH Terms]) AND (english[Language])\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Testing: Broad biomedical search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:58:22\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mFound 5 articles\u001b[0m\n",
      "\u001b[32m2025-09-17 15:58:22\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mSearching PubMed with query: \"hippocampus\"[Abstract] OR \"memory\"[Abstract] OR \"synaptic plasticity\"[Abstract]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Found 5 articles\n",
      "\n",
      "🔍 Testing: Specific neuroscience terms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:58:22\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mFound 5 articles\u001b[0m\n",
      "\u001b[32m2025-09-17 15:58:22\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mSearching PubMed with query: \"cardiac\"[Abstract] OR \"heart\"[Abstract] OR \"cardiovascular\"[Abstract]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Found 5 articles\n",
      "\n",
      "🔍 Testing: Cardiovascular research\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:58:23\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mFound 5 articles\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Found 5 articles\n",
      "\n",
      "📊 Search Results Summary:\n",
      "   Broad biomedical search: 5 articles\n",
      "   Specific neuroscience terms: 5 articles\n",
      "   Cardiovascular research: 5 articles\n"
     ]
    }
   ],
   "source": [
    "# Test different search approaches\n",
    "async def test_search_strategies():\n",
    "    search_tests = [\n",
    "        {\n",
    "            'name': 'Broad biomedical search',\n",
    "            'terms': None,  # Uses default broad search\n",
    "            'days': 7,\n",
    "            'max_results': 5\n",
    "        },\n",
    "        {\n",
    "            'name': 'Specific neuroscience terms',\n",
    "            'terms': ['hippocampus', 'memory', 'synaptic plasticity'],\n",
    "            'days': 14,\n",
    "            'max_results': 5\n",
    "        },\n",
    "        {\n",
    "            'name': 'Cardiovascular research',\n",
    "            'terms': ['cardiac', 'heart', 'cardiovascular'],\n",
    "            'days': 7,\n",
    "            'max_results': 5\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    search_results = {}\n",
    "\n",
    "    for test in search_tests:\n",
    "        print(f\"\\n🔍 Testing: {test['name']}\")\n",
    "        \n",
    "        try:\n",
    "            test_pmids = await searcher.search_recent_articles(\n",
    "                query_terms=test['terms'],\n",
    "                days_back=test['days'],\n",
    "                max_results=test['max_results']\n",
    "            )\n",
    "            \n",
    "            search_results[test['name']] = {\n",
    "                'pmids': test_pmids,\n",
    "                'count': len(test_pmids),\n",
    "                'terms': test['terms']\n",
    "            }\n",
    "            \n",
    "            print(f\"   Found {len(test_pmids)} articles\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed: {e}\")\n",
    "            search_results[test['name']] = {'pmids': [], 'count': 0, 'error': str(e)}\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n📊 Search Results Summary:\")\n",
    "    for name, result in search_results.items():\n",
    "        print(f\"   {name}: {result['count']} articles\")\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "# Run the async function\n",
    "search_results = await test_search_strategies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b664d",
   "metadata": {},
   "source": [
    "## 5. Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9969d873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Data Quality Analysis:\n",
      "\n",
      "Total articles analyzed: 10\n",
      "Articles with abstracts: 8 (80.0%)\n",
      "Articles with DOI: 10 (100.0%)\n",
      "Average abstract length: 551 characters\n",
      "Average author count: 2.3\n",
      "Average MeSH terms: 9.0\n",
      "\n",
      "Top journals:\n",
      "   Current biology : CB: 3\n",
      "   Annual review of neuroscience: 2\n",
      "   Neuron: 1\n",
      "   Acta pharmaceutica (Zagreb, Croatia): 1\n",
      "   Science (New York, N.Y.): 1\n"
     ]
    }
   ],
   "source": [
    "# Analyze data quality if we have articles\n",
    "if articles:\n",
    "    print(\"📊 Data Quality Analysis:\")\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    df_data = []\n",
    "    for article in articles:\n",
    "        df_data.append({\n",
    "            'pmid': article.pmid,\n",
    "            'title_length': len(article.title) if article.title else 0,\n",
    "            'has_abstract': bool(article.abstract),\n",
    "            'abstract_length': len(article.abstract) if article.abstract else 0,\n",
    "            'author_count': len(article.authors) if article.authors else 0,\n",
    "            'has_doi': bool(article.doi),\n",
    "            'mesh_term_count': len(article.mesh_terms) if article.mesh_terms else 0,\n",
    "            'journal': article.journal\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    \n",
    "    print(f\"\\nTotal articles analyzed: {len(df)}\")\n",
    "    print(f\"Articles with abstracts: {df['has_abstract'].sum()} ({df['has_abstract'].mean()*100:.1f}%)\")\n",
    "    print(f\"Articles with DOI: {df['has_doi'].sum()} ({df['has_doi'].mean()*100:.1f}%)\")\n",
    "    print(f\"Average abstract length: {df['abstract_length'].mean():.0f} characters\")\n",
    "    print(f\"Average author count: {df['author_count'].mean():.1f}\")\n",
    "    print(f\"Average MeSH terms: {df['mesh_term_count'].mean():.1f}\")\n",
    "    \n",
    "    # Top journals\n",
    "    top_journals = df['journal'].value_counts().head()\n",
    "    print(f\"\\nTop journals:\")\n",
    "    for journal, count in top_journals.items():\n",
    "        print(f\"   {journal}: {count}\")\n",
    "        \n",
    "else:\n",
    "    print(\"⏭️  No articles available for quality analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76261496",
   "metadata": {},
   "source": [
    "## 6. Save Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb40a846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:59:15\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msave_articles\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mSaved 10 articles to ../data/raw/test_pubmed_articles.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved 10 test articles\n",
      "💾 Saved test summary\n"
     ]
    }
   ],
   "source": [
    "# Save test results\n",
    "output_dir = Path(\"../data/raw\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if articles:\n",
    "    # Save articles\n",
    "    searcher.save_articles(articles, output_dir / \"test_pubmed_articles.json\")\n",
    "    print(f\"💾 Saved {len(articles)} test articles\")\n",
    "    \n",
    "    # Save search results summary\n",
    "    summary = {\n",
    "        'timestamp': pd.Timestamp.now().isoformat(),\n",
    "        'total_articles': len(articles),\n",
    "        'search_results': search_results,\n",
    "        'quality_metrics': {\n",
    "            'articles_with_abstracts': int(df['has_abstract'].sum()),\n",
    "            'articles_with_doi': int(df['has_doi'].sum()),\n",
    "            'avg_abstract_length': float(df['abstract_length'].mean()),\n",
    "            'avg_author_count': float(df['author_count'].mean())\n",
    "        } if 'df' in locals() else {}\n",
    "    }\n",
    "    \n",
    "    with open(output_dir / \"pubmed_test_summary.json\", 'w') as f:\n",
    "        json.dump(summary, f, indent=2, default=str)\n",
    "    \n",
    "    print(\"💾 Saved test summary\")\n",
    "else:\n",
    "    print(\"⏭️  No data to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17233527",
   "metadata": {},
   "source": [
    "## 7. Test Rate Limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cab672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:59:17\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mSearching PubMed with query: \"test\"[Abstract]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕐 Testing rate limiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:59:18\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mFound 2 articles\u001b[0m\n",
      "\u001b[32m2025-09-17 15:59:18\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mSearching PubMed with query: \"test\"[Abstract]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Request 1: 0.53s, 2 PMIDs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:59:19\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mFound 2 articles\u001b[0m\n",
      "\u001b[32m2025-09-17 15:59:19\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mSearching PubMed with query: \"test\"[Abstract]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Request 2: 0.52s, 2 PMIDs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 15:59:19\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mpubmed.searcher\u001b[0m:\u001b[36msearch_recent_articles\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mFound 2 articles\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Request 3: 0.44s, 2 PMIDs\n",
      "\n",
      "Total time for 3 requests: 1.49s\n",
      "Average time per request: 0.50s\n",
      "Successful requests: 3/3\n"
     ]
    }
   ],
   "source": [
    "# Test rate limiting with multiple requests\n",
    "async def test_rate_limiting():\n",
    "    print(\"🕐 Testing rate limiting...\")\n",
    "\n",
    "    import time\n",
    "\n",
    "    rate_test_results = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(3):  # Test 3 requests\n",
    "        request_start = time.time()\n",
    "        \n",
    "        try:\n",
    "            test_pmids = await searcher.search_recent_articles(\n",
    "                query_terms=[\"test\"],\n",
    "                days_back=30,\n",
    "                max_results=2\n",
    "            )\n",
    "            \n",
    "            request_time = time.time() - request_start\n",
    "            rate_test_results.append({\n",
    "                'request': i+1,\n",
    "                'time': request_time,\n",
    "                'pmids_found': len(test_pmids),\n",
    "                'success': True\n",
    "            })\n",
    "            \n",
    "            print(f\"   Request {i+1}: {request_time:.2f}s, {len(test_pmids)} PMIDs\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            rate_test_results.append({\n",
    "                'request': i+1,\n",
    "                'error': str(e),\n",
    "                'success': False\n",
    "            })\n",
    "            print(f\"   Request {i+1}: Failed - {e}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTotal time for {len(rate_test_results)} requests: {total_time:.2f}s\")\n",
    "    print(f\"Average time per request: {total_time/len(rate_test_results):.2f}s\")\n",
    "\n",
    "    successful_requests = [r for r in rate_test_results if r['success']]\n",
    "    print(f\"Successful requests: {len(successful_requests)}/{len(rate_test_results)}\")\n",
    "    \n",
    "    return rate_test_results\n",
    "\n",
    "# Run the async function\n",
    "rate_test_results = await test_rate_limiting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d9271f",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Configure email**: Make sure you have a valid email in the configuration\n",
    "2. **API key**: Consider getting a PubMed API key for higher rate limits\n",
    "3. **Search optimization**: Fine-tune search terms based on IFC research areas\n",
    "4. **Error handling**: Test how the system handles network issues, rate limits, etc.\n",
    "\n",
    "## Common Issues\n",
    "- **Email required**: NCBI requires a valid email address\n",
    "- **Rate limiting**: Too many requests will get blocked\n",
    "- **Network timeouts**: Large requests may timeout\n",
    "- **XML parsing**: Malformed XML responses can cause errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
