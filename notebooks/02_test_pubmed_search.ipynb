{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ef91a1",
   "metadata": {},
   "source": [
    "# PubMed Search Testing Notebook\n",
    "\n",
    "This notebook tests the PubMed search and article retrieval functionality.\n",
    "\n",
    "## Overview\n",
    "- Test PubMed API integration\n",
    "- Search for recent articles\n",
    "- Retrieve article details\n",
    "- Validate data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01611bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f64ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our modules\n",
    "from pubmed.searcher import PubMedSearcher\n",
    "from utils.config import load_config\n",
    "from utils.logger import setup_logger, get_logger\n",
    "\n",
    "# Setup logging\n",
    "setup_logger(level=\"INFO\")\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5573c",
   "metadata": {},
   "source": [
    "## 1. Configure PubMed Access\n",
    "\n",
    "**Important**: You need to set your email in the config for PubMed API access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config()\n",
    "print(\"PubMed configuration:\")\n",
    "print(f\"Email: {config['pubmed']['email']}\")\n",
    "print(f\"Base URL: {config['pubmed']['base_url']}\")\n",
    "print(f\"Rate limit: {config['pubmed']['rate_limit_delay']}s\")\n",
    "print(f\"Max articles per week: {config['pubmed']['max_articles_per_week']}\")\n",
    "\n",
    "if config['pubmed']['email'] == 'your-email@example.com':\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Please update your email in config/config.yaml or .env file\")\n",
    "    print(\"NCBI requires a valid email for API access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a63f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize searcher\n",
    "searcher = PubMedSearcher(config)\n",
    "print(\"PubMed searcher initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c696de",
   "metadata": {},
   "source": [
    "## 2. Test Basic Search\n",
    "\n",
    "Start with a simple search to test the API connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261d6cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test basic search with neuroscience terms\n",
    "test_terms = [\"neuroscience\", \"physiology\"]\n",
    "print(f\"Testing search with terms: {test_terms}\")\n",
    "\n",
    "try:\n",
    "    pmids = await searcher.search_recent_articles(\n",
    "        query_terms=test_terms,\n",
    "        days_back=7,\n",
    "        max_results=10  # Small number for testing\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Search successful! Found {len(pmids)} articles\")\n",
    "    print(f\"Sample PMIDs: {pmids[:5]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Search failed: {e}\")\n",
    "    pmids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b28f7",
   "metadata": {},
   "source": [
    "## 3. Test Article Detail Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c9780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test fetching details for found articles\n",
    "if pmids:\n",
    "    print(f\"Fetching details for {len(pmids)} articles...\")\n",
    "    \n",
    "    try:\n",
    "        articles = await searcher.fetch_article_details(pmids)\n",
    "        print(f\"‚úÖ Retrieved details for {len(articles)} articles\")\n",
    "        \n",
    "        if articles:\n",
    "            sample = articles[0]\n",
    "            print(\"\\nüìÑ Sample article:\")\n",
    "            print(f\"PMID: {sample.pmid}\")\n",
    "            print(f\"Title: {sample.title}\")\n",
    "            print(f\"Authors: {', '.join(sample.authors[:3]) if sample.authors else 'No authors'}\")\n",
    "            print(f\"Journal: {sample.journal}\")\n",
    "            print(f\"Publication Date: {sample.publication_date}\")\n",
    "            print(f\"DOI: {sample.doi}\")\n",
    "            print(f\"Abstract length: {len(sample.abstract) if sample.abstract else 0} characters\")\n",
    "            print(f\"MeSH terms: {sample.mesh_terms[:5] if sample.mesh_terms else 'None'}\")\n",
    "            \n",
    "            if sample.abstract:\n",
    "                print(f\"\\nAbstract preview: {sample.abstract[:200]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Detail retrieval failed: {e}\")\n",
    "        articles = []\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping detail retrieval (no PMIDs found)\")\n",
    "    articles = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fdf9a4",
   "metadata": {},
   "source": [
    "## 4. Test Different Search Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb83b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different search approaches\n",
    "search_tests = [\n",
    "    {\n",
    "        'name': 'Broad biomedical search',\n",
    "        'terms': None,  # Uses default broad search\n",
    "        'days': 7,\n",
    "        'max_results': 5\n",
    "    },\n",
    "    {\n",
    "        'name': 'Specific neuroscience terms',\n",
    "        'terms': ['hippocampus', 'memory', 'synaptic plasticity'],\n",
    "        'days': 14,\n",
    "        'max_results': 5\n",
    "    },\n",
    "    {\n",
    "        'name': 'Cardiovascular research',\n",
    "        'terms': ['cardiac', 'heart', 'cardiovascular'],\n",
    "        'days': 7,\n",
    "        'max_results': 5\n",
    "    }\n",
    "]\n",
    "\n",
    "search_results = {}\n",
    "\n",
    "for test in search_tests:\n",
    "    print(f\"\\nüîç Testing: {test['name']}\")\n",
    "    \n",
    "    try:\n",
    "        test_pmids = await searcher.search_recent_articles(\n",
    "            query_terms=test['terms'],\n",
    "            days_back=test['days'],\n",
    "            max_results=test['max_results']\n",
    "        )\n",
    "        \n",
    "        search_results[test['name']] = {\n",
    "            'pmids': test_pmids,\n",
    "            'count': len(test_pmids),\n",
    "            'terms': test['terms']\n",
    "        }\n",
    "        \n",
    "        print(f\"   Found {len(test_pmids)} articles\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Failed: {e}\")\n",
    "        search_results[test['name']] = {'pmids': [], 'count': 0, 'error': str(e)}\n",
    "\n",
    "# Summary\n",
    "print(\"\\nüìä Search Results Summary:\")\n",
    "for name, result in search_results.items():\n",
    "    print(f\"   {name}: {result['count']} articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b664d",
   "metadata": {},
   "source": [
    "## 5. Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data quality if we have articles\n",
    "if articles:\n",
    "    print(\"üìä Data Quality Analysis:\")\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    df_data = []\n",
    "    for article in articles:\n",
    "        df_data.append({\n",
    "            'pmid': article.pmid,\n",
    "            'title_length': len(article.title) if article.title else 0,\n",
    "            'has_abstract': bool(article.abstract),\n",
    "            'abstract_length': len(article.abstract) if article.abstract else 0,\n",
    "            'author_count': len(article.authors) if article.authors else 0,\n",
    "            'has_doi': bool(article.doi),\n",
    "            'mesh_term_count': len(article.mesh_terms) if article.mesh_terms else 0,\n",
    "            'journal': article.journal\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    \n",
    "    print(f\"\\nTotal articles analyzed: {len(df)}\")\n",
    "    print(f\"Articles with abstracts: {df['has_abstract'].sum()} ({df['has_abstract'].mean()*100:.1f}%)\")\n",
    "    print(f\"Articles with DOI: {df['has_doi'].sum()} ({df['has_doi'].mean()*100:.1f}%)\")\n",
    "    print(f\"Average abstract length: {df['abstract_length'].mean():.0f} characters\")\n",
    "    print(f\"Average author count: {df['author_count'].mean():.1f}\")\n",
    "    print(f\"Average MeSH terms: {df['mesh_term_count'].mean():.1f}\")\n",
    "    \n",
    "    # Top journals\n",
    "    top_journals = df['journal'].value_counts().head()\n",
    "    print(f\"\\nTop journals:\")\n",
    "    for journal, count in top_journals.items():\n",
    "        print(f\"   {journal}: {count}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  No articles available for quality analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76261496",
   "metadata": {},
   "source": [
    "## 6. Save Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb40a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test results\n",
    "output_dir = Path(\"../data/raw\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if articles:\n",
    "    # Save articles\n",
    "    searcher.save_articles(articles, output_dir / \"test_pubmed_articles.json\")\n",
    "    print(f\"üíæ Saved {len(articles)} test articles\")\n",
    "    \n",
    "    # Save search results summary\n",
    "    summary = {\n",
    "        'timestamp': pd.Timestamp.now().isoformat(),\n",
    "        'total_articles': len(articles),\n",
    "        'search_results': search_results,\n",
    "        'quality_metrics': {\n",
    "            'articles_with_abstracts': int(df['has_abstract'].sum()),\n",
    "            'articles_with_doi': int(df['has_doi'].sum()),\n",
    "            'avg_abstract_length': float(df['abstract_length'].mean()),\n",
    "            'avg_author_count': float(df['author_count'].mean())\n",
    "        } if 'df' in locals() else {}\n",
    "    }\n",
    "    \n",
    "    with open(output_dir / \"pubmed_test_summary.json\", 'w') as f:\n",
    "        json.dump(summary, f, indent=2, default=str)\n",
    "    \n",
    "    print(\"üíæ Saved test summary\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  No data to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17233527",
   "metadata": {},
   "source": [
    "## 7. Test Rate Limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test rate limiting with multiple requests\n",
    "print(\"üïê Testing rate limiting...\")\n",
    "\n",
    "import time\n",
    "\n",
    "rate_test_results = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(3):  # Test 3 requests\n",
    "    request_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        test_pmids = await searcher.search_recent_articles(\n",
    "            query_terms=[\"test\"],\n",
    "            days_back=30,\n",
    "            max_results=2\n",
    "        )\n",
    "        \n",
    "        request_time = time.time() - request_start\n",
    "        rate_test_results.append({\n",
    "            'request': i+1,\n",
    "            'time': request_time,\n",
    "            'pmids_found': len(test_pmids),\n",
    "            'success': True\n",
    "        })\n",
    "        \n",
    "        print(f\"   Request {i+1}: {request_time:.2f}s, {len(test_pmids)} PMIDs\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        rate_test_results.append({\n",
    "            'request': i+1,\n",
    "            'error': str(e),\n",
    "            'success': False\n",
    "        })\n",
    "        print(f\"   Request {i+1}: Failed - {e}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTotal time for {len(rate_test_results)} requests: {total_time:.2f}s\")\n",
    "print(f\"Average time per request: {total_time/len(rate_test_results):.2f}s\")\n",
    "\n",
    "successful_requests = [r for r in rate_test_results if r['success']]\n",
    "print(f\"Successful requests: {len(successful_requests)}/{len(rate_test_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d9271f",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Configure email**: Make sure you have a valid email in the configuration\n",
    "2. **API key**: Consider getting a PubMed API key for higher rate limits\n",
    "3. **Search optimization**: Fine-tune search terms based on IFC research areas\n",
    "4. **Error handling**: Test how the system handles network issues, rate limits, etc.\n",
    "\n",
    "## Common Issues\n",
    "- **Email required**: NCBI requires a valid email address\n",
    "- **Rate limiting**: Too many requests will get blocked\n",
    "- **Network timeouts**: Large requests may timeout\n",
    "- **XML parsing**: Malformed XML responses can cause errors"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
