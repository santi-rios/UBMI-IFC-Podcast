{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae460b7",
   "metadata": {},
   "source": [
    "# ðŸ“Š Full Database Embeddings Analysis & Visualization\n",
    "\n",
    "This notebook performs comprehensive analysis of the expanded IFC publication database using embeddings and creates various visualizations to understand the research landscape.\n",
    "\n",
    "## What This Notebook Does:\n",
    "- Loads the complete expanded database (IFC + PubMed articles)\n",
    "- Generates embeddings for all publications using Google Gemini\n",
    "- Creates 2D/3D visualizations using t-SNE and UMAP\n",
    "- Performs clustering analysis\n",
    "- Builds similarity networks\n",
    "- Compares IFC vs PubMed article distributions\n",
    "- Identifies research themes and trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beac432",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ML and embeddings\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "# Google Gemini for embeddings\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Network analysis\n",
    "import networkx as nx\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b466d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "tqdm.pandas()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"ðŸ“Š Visualization settings configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049fcd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the expanded database\n",
    "database_path = 'data/processed/expanded_ifc_publications.json'\n",
    "\n",
    "try:\n",
    "    with open(database_path, 'r', encoding='utf-8') as f:\n",
    "        database_data = json.load(f)\n",
    "    \n",
    "    publications = database_data['publications']\n",
    "    metadata = database_data['metadata']\n",
    "    \n",
    "    print(f\"ðŸ“š Loaded {len(publications)} publications from expanded database\")\n",
    "    print(f\"ðŸ“Š Database metadata:\")\n",
    "    print(f\"   â€¢ Total publications: {metadata['total_publications']}\")\n",
    "    print(f\"   â€¢ Last updated: {metadata['last_updated']}\")\n",
    "    print(f\"   â€¢ Original IFC articles: {metadata['sources']['original_ifc_scraping']}\")\n",
    "    print(f\"   â€¢ New PubMed articles: {metadata['sources']['pubmed_filtered_search']}\")\n",
    "    print(f\"   â€¢ New articles added: {metadata['new_articles_added']}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Expanded database not found. Please run the database expansion notebook first.\")\n",
    "    print(\"Expected file: data/processed/expanded_ifc_publications.json\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "df = pd.DataFrame(publications)\n",
    "\n",
    "# Add source column to distinguish IFC vs PubMed articles\n",
    "df['source_type'] = df['metadata'].apply(\n",
    "    lambda x: 'PubMed' if x.get('source') == 'PubMed_filtered_search' else 'IFC'\n",
    ")\n",
    "\n",
    "# Create text for embedding (title + abstract)\n",
    "df['embedding_text'] = df['title'].fillna('') + ' ' + df['abstract'].fillna('')\n",
    "df['embedding_text'] = df['embedding_text'].str.strip()\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"ðŸ“Š Dataset Overview:\")\n",
    "print(f\"   â€¢ Total articles: {len(df)}\")\n",
    "print(f\"   â€¢ IFC articles: {len(df[df['source_type'] == 'IFC'])}\")\n",
    "print(f\"   â€¢ PubMed articles: {len(df[df['source_type'] == 'PubMed'])}\")\n",
    "print(f\"   â€¢ Articles with abstracts: {len(df[df['abstract'].notna()])}\")\n",
    "print(f\"   â€¢ Year range: {df['year'].min()} - {df['year'].max()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b95e9",
   "metadata": {},
   "source": [
    "## 2. Google Gemini Setup for Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8145a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Gemini client\n",
    "# Make sure you have GEMINI_API_KEY in your environment\n",
    "import os\n",
    "\n",
    "try:\n",
    "    api_key = os.getenv('GEMINI_API_KEY')\n",
    "    if not api_key:\n",
    "        print(\"âš ï¸  GEMINI_API_KEY not found in environment variables.\")\n",
    "        print(\"Please set it with: export GEMINI_API_KEY='your-api-key'\")\n",
    "        # For testing purposes, you can uncomment and set it directly:\n",
    "        # api_key = 'your-api-key-here'\n",
    "        raise ValueError(\"API key required\")\n",
    "    \n",
    "    client = genai.Client(api_key=api_key)\n",
    "    print(\"âœ… Gemini client initialized successfully\")\n",
    "    \n",
    "    # List available embedding models\n",
    "    print(\"\\nðŸ“‹ Available embedding models:\")\n",
    "    for m in client.models.list():\n",
    "        if 'embedContent' in m.supported_actions:\n",
    "            print(f\"   â€¢ {m.name}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error setting up Gemini client: {e}\")\n",
    "    print(\"\\nðŸ’¡ Alternative: You can load pre-computed embeddings if available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select embedding model\n",
    "MODEL_ID = \"gemini-embedding-001\"\n",
    "print(f\"ðŸŽ¯ Using embedding model: {MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12668c6",
   "metadata": {},
   "source": [
    "## 3. Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a67219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embed_text_fn(model_id, client):\n",
    "    \"\"\"Create embedding function for batch processing\"\"\"\n",
    "    \n",
    "    def embed_fn(text: str) -> list[float]:\n",
    "        \"\"\"Generate embedding for a single text\"\"\"\n",
    "        try:\n",
    "            result = client.models.embed_content(\n",
    "                model=model_id,\n",
    "                contents=text,\n",
    "                config=types.EmbedContentConfig(task_type=\"CLUSTERING\")\n",
    "            )\n",
    "            return np.array(result.embeddings[0].values)\n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding text: {str(e)[:100]}...\")\n",
    "            # Return zero vector as fallback\n",
    "            return np.zeros(768)  # Default embedding size for gemini-embedding-001\n",
    "    \n",
    "    return embed_fn\n",
    "\n",
    "# Create embedding function\n",
    "embed_fn = make_embed_text_fn(MODEL_ID, client)\n",
    "print(\"ðŸ”§ Embedding function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if embeddings already exist\n",
    "embeddings_file = 'data/processed/publication_embeddings.npy'\n",
    "embeddings_meta_file = 'data/processed/publication_embeddings_meta.json'\n",
    "\n",
    "if os.path.exists(embeddings_file) and os.path.exists(embeddings_meta_file):\n",
    "    print(\"ðŸ“ Found existing embeddings, loading...\")\n",
    "    embeddings = np.load(embeddings_file)\n",
    "    with open(embeddings_meta_file, 'r') as f:\n",
    "        emb_meta = json.load(f)\n",
    "    print(f\"âœ… Loaded {embeddings.shape[0]} embeddings of dimension {embeddings.shape[1]}\")\n",
    "    \n",
    "else:\n",
    "    print(\"ðŸ”„ Generating embeddings for all publications...\")\n",
    "    print(f\"ðŸ“Š Processing {len(df)} publications\")\n",
    "    \n",
    "    # Filter out empty texts\n",
    "    df_embed = df[df['embedding_text'].str.len() > 10].copy()\n",
    "    print(f\"ðŸ“‹ {len(df_embed)} publications have sufficient text for embedding\")\n",
    "    \n",
    "    # Generate embeddings with progress bar\n",
    "    embeddings_list = []\n",
    "    failed_indices = []\n",
    "    \n",
    "    for idx, text in tqdm(df_embed['embedding_text'].items(), \n",
    "                         desc=\"Generating embeddings\", \n",
    "                         total=len(df_embed)):\n",
    "        try:\n",
    "            embedding = embed_fn(text[:8000])  # Limit text length\n",
    "            embeddings_list.append(embedding)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to embed article {idx}: {e}\")\n",
    "            failed_indices.append(idx)\n",
    "            embeddings_list.append(np.zeros(768))  # Zero vector fallback\n",
    "    \n",
    "    embeddings = np.array(embeddings_list)\n",
    "    \n",
    "    # Save embeddings for future use\n",
    "    os.makedirs('data/processed', exist_ok=True)\n",
    "    np.save(embeddings_file, embeddings)\n",
    "    \n",
    "    emb_meta = {\n",
    "        'model': MODEL_ID,\n",
    "        'generated_at': datetime.now().isoformat(),\n",
    "        'total_embeddings': len(embeddings),\n",
    "        'embedding_dimension': embeddings.shape[1],\n",
    "        'failed_indices': failed_indices\n",
    "    }\n",
    "    \n",
    "    with open(embeddings_meta_file, 'w') as f:\n",
    "        json.dump(emb_meta, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ… Generated and saved {len(embeddings)} embeddings\")\n",
    "    print(f\"ðŸ’¾ Saved to: {embeddings_file}\")\n",
    "\n",
    "# Add embeddings to dataframe\n",
    "if len(embeddings) == len(df):\n",
    "    df['embedding'] = [emb for emb in embeddings]\n",
    "else:\n",
    "    # Handle case where we filtered some articles\n",
    "    print(f\"âš ï¸  Embedding count mismatch. Adjusting...\")\n",
    "    # Add embeddings only to articles that have sufficient text\n",
    "    df_embed = df[df['embedding_text'].str.len() > 10].copy()\n",
    "    df = df_embed.copy()\n",
    "    df['embedding'] = [emb for emb in embeddings]\n",
    "\n",
    "print(f\"ðŸ“Š Final dataset: {len(df)} publications with embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4dbf9a",
   "metadata": {},
   "source": [
    "## 4. Dimensionality Reduction & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8612fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare embeddings matrix\n",
    "embeddings_matrix = np.stack(df['embedding'].values)\n",
    "print(f\"ðŸ“Š Embeddings matrix shape: {embeddings_matrix.shape}\")\n",
    "\n",
    "# t-SNE visualization\n",
    "print(\"ðŸ”„ Computing t-SNE...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(embeddings_matrix)\n",
    "\n",
    "df['tsne_x'] = tsne_results[:, 0]\n",
    "df['tsne_y'] = tsne_results[:, 1]\n",
    "\n",
    "print(\"âœ… t-SNE completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74583478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP visualization\n",
    "print(\"ðŸ”„ Computing UMAP...\")\n",
    "umap_reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "umap_results = umap_reducer.fit_transform(embeddings_matrix)\n",
    "\n",
    "df['umap_x'] = umap_results[:, 0]\n",
    "df['umap_y'] = umap_results[:, 1]\n",
    "\n",
    "print(\"âœ… UMAP completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive t-SNE plot\n",
    "fig = px.scatter(\n",
    "    df, \n",
    "    x='tsne_x', \n",
    "    y='tsne_y', \n",
    "    color='source_type',\n",
    "    hover_data={'title': True, 'year': True, 'journal': True},\n",
    "    title='t-SNE Visualization of Publication Embeddings',\n",
    "    width=800, \n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_x=0.5,\n",
    "    showlegend=True,\n",
    "    xaxis_title=\"t-SNE Dimension 1\",\n",
    "    yaxis_title=\"t-SNE Dimension 2\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"ðŸ“Š Interactive t-SNE plot generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive UMAP plot\n",
    "fig = px.scatter(\n",
    "    df, \n",
    "    x='umap_x', \n",
    "    y='umap_y', \n",
    "    color='source_type',\n",
    "    hover_data={'title': True, 'year': True, 'journal': True},\n",
    "    title='UMAP Visualization of Publication Embeddings',\n",
    "    width=800, \n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_x=0.5,\n",
    "    showlegend=True,\n",
    "    xaxis_title=\"UMAP Dimension 1\",\n",
    "    yaxis_title=\"UMAP Dimension 2\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"ðŸ“Š Interactive UMAP plot generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49907cc5",
   "metadata": {},
   "source": [
    "## 5. Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering\n",
    "print(\"ðŸ”„ Performing K-means clustering...\")\n",
    "\n",
    "# Test different numbers of clusters\n",
    "k_range = range(3, 12)\n",
    "inertias = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(embeddings_matrix)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertias, 'bo-')\n",
    "plt.title('K-means Elbow Method')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Choose optimal k (you can adjust this)\n",
    "optimal_k = 6\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(embeddings_matrix)\n",
    "\n",
    "df['cluster'] = cluster_labels\n",
    "\n",
    "print(f\"âœ… K-means clustering completed with {optimal_k} clusters\")\n",
    "print(\"ðŸ“Š Cluster sizes:\")\n",
    "print(df['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58fd5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clusters on t-SNE\n",
    "fig = px.scatter(\n",
    "    df, \n",
    "    x='tsne_x', \n",
    "    y='tsne_y', \n",
    "    color='cluster',\n",
    "    symbol='source_type',\n",
    "    hover_data={'title': True, 'year': True, 'journal': True},\n",
    "    title=f't-SNE Visualization with {optimal_k} Clusters',\n",
    "    width=900, \n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig.update_layout(title_x=0.5)\n",
    "fig.show()\n",
    "\n",
    "print(\"ðŸ“Š Cluster visualization generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136a2d4",
   "metadata": {},
   "source": [
    "## 6. Source Comparison Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare IFC vs PubMed distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Cluster distribution by source\n",
    "cluster_source = pd.crosstab(df['cluster'], df['source_type'], normalize='columns')\n",
    "cluster_source.plot(kind='bar', ax=axes[0,0], title='Cluster Distribution by Source')\n",
    "axes[0,0].set_ylabel('Proportion')\n",
    "axes[0,0].legend(title='Source')\n",
    "\n",
    "# Year distribution by source\n",
    "df.groupby(['source_type', 'year']).size().unstack(fill_value=0).T.plot(\n",
    "    kind='line', ax=axes[0,1], title='Publication Timeline by Source'\n",
    ")\n",
    "axes[0,1].set_ylabel('Number of Publications')\n",
    "axes[0,1].legend(title='Source')\n",
    "\n",
    "# Abstract length distribution\n",
    "df['abstract_length'] = df['abstract'].fillna('').str.len()\n",
    "df.boxplot(column='abstract_length', by='source_type', ax=axes[1,0])\n",
    "axes[1,0].set_title('Abstract Length Distribution by Source')\n",
    "axes[1,0].set_xlabel('Source Type')\n",
    "\n",
    "# Cluster sizes\n",
    "cluster_sizes = df['cluster'].value_counts().sort_index()\n",
    "cluster_sizes.plot(kind='bar', ax=axes[1,1], title='Cluster Sizes')\n",
    "axes[1,1].set_ylabel('Number of Publications')\n",
    "axes[1,1].set_xlabel('Cluster ID')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“Š Source comparison analysis completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee087417",
   "metadata": {},
   "source": [
    "## 7. Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb0d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pairwise similarities (sample for performance)\n",
    "sample_size = min(200, len(df))  # Limit for computational efficiency\n",
    "sample_indices = np.random.choice(len(df), sample_size, replace=False)\n",
    "sample_df = df.iloc[sample_indices].copy()\n",
    "sample_embeddings = embeddings_matrix[sample_indices]\n",
    "\n",
    "print(f\"ðŸ“Š Computing similarities for {sample_size} sample publications...\")\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(sample_embeddings)\n",
    "\n",
    "# Plot similarity heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(similarity_matrix, \n",
    "            cmap='viridis', \n",
    "            center=0.5,\n",
    "            square=True,\n",
    "            cbar_kws={\"shrink\": .8})\n",
    "plt.title(f'Cosine Similarity Heatmap ({sample_size} publications)')\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“Š Similarity heatmap generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45668cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar publications\n",
    "def find_most_similar_publications(df, embeddings, query_idx, top_k=5):\n",
    "    \"\"\"Find most similar publications to a given publication\"\"\"\n",
    "    query_embedding = embeddings[query_idx].reshape(1, -1)\n",
    "    similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
    "    \n",
    "    # Get top k most similar (excluding the query itself)\n",
    "    top_indices = np.argsort(similarities)[::-1][1:top_k+1]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            'index': idx,\n",
    "            'similarity': similarities[idx],\n",
    "            'title': df.iloc[idx]['title'],\n",
    "            'year': df.iloc[idx]['year'],\n",
    "            'source': df.iloc[idx]['source_type']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example: Find similar publications to the first article\n",
    "query_idx = 0\n",
    "similar_pubs = find_most_similar_publications(df, embeddings_matrix, query_idx)\n",
    "\n",
    "print(f\"ðŸ” Publications most similar to: '{df.iloc[query_idx]['title']}'\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, pub in enumerate(similar_pubs, 1):\n",
    "    print(f\"{i}. Similarity: {pub['similarity']:.3f} | {pub['source']} | {pub['year']}\")\n",
    "    print(f\"   {pub['title'][:80]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5992cf7",
   "metadata": {},
   "source": [
    "## 8. Insights & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806410c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics\n",
    "print(\"ðŸ” CLUSTER ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for cluster_id in sorted(df['cluster'].unique()):\n",
    "    cluster_data = df[df['cluster'] == cluster_id]\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Cluster {cluster_id} ({len(cluster_data)} publications):\")\n",
    "    print(f\"   â€¢ IFC articles: {len(cluster_data[cluster_data['source_type'] == 'IFC'])}\")\n",
    "    print(f\"   â€¢ PubMed articles: {len(cluster_data[cluster_data['source_type'] == 'PubMed'])}\")\n",
    "    \n",
    "    # Year range\n",
    "    years = cluster_data['year'].dropna()\n",
    "    if len(years) > 0:\n",
    "        print(f\"   â€¢ Year range: {years.min()} - {years.max()}\")\n",
    "    \n",
    "    # Top journals\n",
    "    top_journals = cluster_data['journal'].value_counts().head(3)\n",
    "    if len(top_journals) > 0:\n",
    "        print(f\"   â€¢ Top journals: {', '.join(top_journals.index[:3])}\")\n",
    "    \n",
    "    # Sample titles\n",
    "    sample_titles = cluster_data['title'].dropna().head(3)\n",
    "    print(f\"   â€¢ Sample titles:\")\n",
    "    for title in sample_titles:\n",
    "        print(f\"     - {title[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary statistics\n",
    "print(\"\\nðŸŽ¯ FINAL ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"ðŸ“š Total Publications Analyzed: {len(df)}\")\n",
    "print(f\"   â€¢ Original IFC publications: {len(df[df['source_type'] == 'IFC'])}\")\n",
    "print(f\"   â€¢ New PubMed publications: {len(df[df['source_type'] == 'PubMed'])}\")\n",
    "\n",
    "print(f\"\\nðŸ”¬ Embeddings Analysis:\")\n",
    "print(f\"   â€¢ Embedding model: {MODEL_ID}\")\n",
    "print(f\"   â€¢ Embedding dimension: {embeddings_matrix.shape[1]}\")\n",
    "print(f\"   â€¢ Clustering algorithm: K-means with {optimal_k} clusters\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Research Coverage:\")\n",
    "year_range = df['year'].max() - df['year'].min()\n",
    "print(f\"   â€¢ Time span: {year_range} years ({df['year'].min()} - {df['year'].max()})\")\n",
    "print(f\"   â€¢ Unique journals: {df['journal'].nunique()}\")\n",
    "print(f\"   â€¢ Publications with abstracts: {len(df[df['abstract'].notna()])} ({len(df[df['abstract'].notna()])/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸŽ¨ Visualizations Generated:\")\n",
    "print(f\"   â€¢ t-SNE 2D embedding visualization\")\n",
    "print(f\"   â€¢ UMAP 2D embedding visualization\")\n",
    "print(f\"   â€¢ Cluster analysis plots\")\n",
    "print(f\"   â€¢ Source comparison analysis\")\n",
    "print(f\"   â€¢ Similarity heatmaps\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ Files Saved:\")\n",
    "print(f\"   â€¢ {embeddings_file}\")\n",
    "print(f\"   â€¢ {embeddings_meta_file}\")\n",
    "\n",
    "print(\"\\nâœ… Embeddings analysis completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e44d4c",
   "metadata": {},
   "source": [
    "## ðŸš€ Next Steps\n",
    "\n",
    "After running this analysis, you can:\n",
    "\n",
    "1. **Explore specific clusters** - Dive deep into publications within each cluster\n",
    "2. **Topic modeling** - Use the embeddings for more sophisticated topic analysis\n",
    "3. **Recommendation system** - Build a publication recommendation engine\n",
    "4. **Time series analysis** - Analyze how research themes evolve over time\n",
    "5. **Network analysis** - Create citation networks or collaboration graphs\n",
    "6. **Podcast generation** - Use cluster information to generate themed podcasts\n",
    "\n",
    "The embeddings and analysis results are saved and can be used in subsequent notebooks!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
